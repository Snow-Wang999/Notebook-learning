# 391-数字图像增强

## 是什么让神经网络在图像增强和插帧上有着比较好的效果呢？

我们知道，数字视频的清晰度一般由**分辨率和帧率**决定（暂且不考虑影响图像压缩质量的码率）。神经网络对视频的增强，也主要集中在这两种参数上。

### 分辨率增强*

首先我们来谈谈分辨率增强，想要将一张低分辨率的图片变成高分辨率的图片，我们就需要猜测**放大产生的未知像素**。通常情况下，我们会采用某种插值算法进行计算，在图像边缘的模糊和锯齿间获得平衡，这种计算通常无法增加图像细节，即使放大了图像，依旧显得很模糊。

神经网络在增强分辨率上就有着独到的优势，或许你之前曾经听说过一个软件waifu2x ，动漫爱好者们经常用它来放大动漫插图。当然，它同样可以用作照片放大。

waifu2x的核心方法：**通过机器学习，训练一个端到端的网络，使用低分辨率的图像作为输入得到对应的高分辨率结果图像，最后得到的结果在图像的锯齿与模糊程度有较好表现，其训练的原理类似于FCN模型。**

在效果上，waifu2x的**SRCNN（超分辨率卷积神经网络）**要好于传统的双三次插值算法。

当然，waifu2x的算法仅能在静态图片上使用。不过方法都是相同的，madvr 中放大视频分辨率的**ngu算法**也是类似的原理。

### 视频插帧

对于视频插帧来说，神经网络也有自己的用武之地，之前英伟达发布了一个叫做Super SloMo的神经网络，能通过联合建模的运动解释和遮挡推理配合光流算法生成中间帧。

这种技术能将原本30帧的视频放慢到240帧，并在其中添加画面的运动细节。

华为Mate 30 Pro的7680帧慢动作，也是通过神经网络对1080P/960fps 的视频插帧生成的。可见类似的**神经网络插帧算法**确实有很高的使用价值。



## kaggle-学习课程(加载数据库)

```python
# Imports
import os, warnings
import matplotlib.pyplot as plt
from matplotlib import gridspec

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.preprocessing import image_dataset_from_directory
# these are a new feature in TF 2.2
from tensorflow.keras.layers.experimental import preprocessing

# Reproducability
def set_seed(seed=31415):
    np.random.seed(seed)
    tf.random.set_seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    os.environ['TF_DETERMINISTIC_OPS'] = '1'
set_seed()

# Set Matplotlib defaults
plt.rc('figure', autolayout=True)
plt.rc('axes', labelweight='bold', labelsize='large',
       titleweight='bold', titlesize=18, titlepad=10)
plt.rc('image', cmap='magma')
warnings.filterwarnings("ignore") 
# to clean up output cells

# Load training and validation sets
ds_train_ = image_dataset_from_directory(
    '../input/image-super-resolution/dataset/train',
    labels='inferred',
    label_mode='binary',
    image_size=[256, 256],
    interpolation='nearest',
    batch_size=64,
    shuffle=True,
)
ds_valid_ = image_dataset_from_directory(
    '../input/image-super-resolution/dataset/val',
    labels='inferred',
    label_mode='binary',
    image_size=[256, 256],
    interpolation='nearest',
    batch_size=64,
    shuffle=False,
)

# Data Pipeline
def convert_to_float(image, label):
    image = tf.image.convert_image_dtype(image, dtype=tf.float32)
    return image, label

AUTOTUNE = tf.data.experimental.AUTOTUNE
ds_train = (
    ds_train_
    .map(convert_to_float)
    .cache()
    .prefetch(buffer_size=AUTOTUNE)
)
ds_valid = (
    ds_valid_
    .map(convert_to_float)
    .cache()
    .prefetch(buffer_size=AUTOTUNE)
)
```

另一种方式如下：

## 加载环境库

```python
import numpy as np
import tensorflow as tf
import keras
import cv2
from keras.models import Sequential
from keras.preprocessing.image import img_to_array
import os
from tqdm import tqdm
import re
import matplotlib.pyplot as plt
```

## 数据读取

```python
# to get the files in proper order
def sorted_alphanumeric(data):  
    convert = lambda text: int(text) if text.isdigit() else text.lower()
    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)',key)]
    return sorted(data,key = alphanum_key)
# defining the size of the image
SIZE = 256
high_img = []
path = '../input/image-super-resolution/dataset/Raw Data/high_res'
files = os.listdir(path)
files = sorted_alphanumeric(files)
for i in tqdm(files):    
    if i == '855.jpg':
        break
    else:    
        img = cv2.imread(path + '/'+i,1)
        # open cv reads images in BGR format so we have to convert it to RGB
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        #resizing image
        img = cv2.resize(img, (SIZE, SIZE))
        img = img.astype('float32') / 255.0
        high_img.append(img_to_array(img))


low_img = []
path = '../input/image-super-resolution/dataset/Raw Data/low_res'
files = os.listdir(path)
files = sorted_alphanumeric(files)
for i in tqdm(files):
     if i == '855.jpg':
        break
     else: 
        img = cv2.imread(path + '/'+i,1)

        #resizing image
        img = cv2.resize(img, (SIZE, SIZE))
        img = img.astype('float32') / 255.0
        low_img.append(img_to_array(img))
```



## 图像读取-数据类型改变

https://blog.csdn.net/cxx654/article/details/98373018

```python
image_path = "./images/panda.jpg"
img = cv2.imread(image_path)
img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)
print(np.min(img),np.max(img))
plt.imshow(img)
plt.show()
```

0 255

<img src="C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221108222554131.png" alt="image-20221108222554131" style="zoom:50%;" />

1、`tf.image.convert_image_dtype` 把uint转为float的tensor，自动对数据进行归一化处理，将数据缩放到0-1范围

```python
img_rgb_tf_float = tf.image.convert_image_dytpe(img,tf.float32)
img_rgb_tf_float = sess.run(img_rgb_tf_float)
print(np.min(img_rgb_tf_float),np.max(img_rgb_tf_float))
plt.imshow(img_rgb_tf_float)
plt.show()
```

0.0 1.0

<img src="C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221108222632086.png" alt="image-20221108222632086" style="zoom:50%;" />

2、`tf.cast` 把uint转为float的tensor，但数据范围没有发生变化，还是0-255，不会归一化

```python
img_rgb_tf_float = tf.cast(img,tf.float32)
img_rgb_tf_float = sess.run(img_rgb_tf_float)
img_rgb_tf_int = img_rgb_tf_float.astype(np.int32)
print(np.min(img_rgb_tf_int),np.max(img_rgb_tf_int))
plt.imshow(img_rgb_tf_int)
plt.show()
```

0 255

<img src="C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221108222520692.png" alt="image-20221108222520692" style="zoom:50%;" />

3、`tensor`和`numpy` 互相转换

- tensor转换为numpy------`sess.run(tensor)`
- numpy转换为tensor------`tf.convert_to_tensor(numpy)`

## 数据可视化

```python
for i in range(4):
    a = np.random.randint(0,855)
    plt.figure(figsize=(10,10))
    plt.subplot(1,2,1)
    plt.title('High Resolution Imge', color = 'green', fontsize = 20)
    plt.imshow(high_img[a])
    plt.axis('off')
    plt.subplot(1,2,2)
    plt.title('low Resolution Image ', color = 'black', fontsize = 20)
    plt.imshow(low_img[a])
    plt.axis('off')
```

## 切片和重塑图像

```python
train_high_image = high_img[:700]
train_low_image = low_img[:700]
train_high_image = np.reshape(train_high_image,(len(train_high_image),SIZE,SIZE,3))
train_low_image = np.reshape(train_low_image,(len(train_low_image),SIZE,SIZE,3))

validation_high_image = high_img[700:830]
validation_low_image = low_img[700:830]
validation_high_image= np.reshape(validation_high_image,(len(validation_high_image),SIZE,SIZE,3))
validation_low_image = np.reshape(validation_low_image,(len(validation_low_image),SIZE,SIZE,3))


test_high_image = high_img[830:]
test_low_image = low_img[830:]
test_high_image= np.reshape(test_high_image,(len(test_high_image),SIZE,SIZE,3))
test_low_image = np.reshape(test_low_image,(len(test_low_image),SIZE,SIZE,3))

print("Shape of training images:",train_high_image.shape)
print("Shape of test images:",test_high_image.shape)
print("Shape of validation images:",validation_high_image.shape)
```



## 添加高斯噪声

```python
#对图像添加高斯噪声
def add_gauss_noise(image,mean=0,val=0.01):
    size = image.shape
    #对图像归一化处理
    image = image /255
    gauss = np.random.normal(mean, val**0.05, size)
    image = image + gauss
    return image
```

## 高斯滤波

### python 手动实现`cv2.GaussianBlur()`

[python opencv手动实现cv2.GaussianBlur](https://blog.csdn.net/TTTree_/article/details/125429514)

为了研究`cv2.GaussianBlur()`内部的计算逻辑

```python
ta = cv2.GaussianBlur(img, (kernel, kernel), 0)
```

可以分为两部分:

- 第一步获取高斯核。

  设高斯kernel=3,sigma=0, 可得高斯核为: 

  ```python
  kernel=3
  sigma=0
  ka = gaussian_kernel_2d(kernel, sigma)
  '''
  or
  kernel = tf.constant(
  					[0.0625,0.125,0.0625],
  					[0.125, 0.25, 0.125],
  					[0.0625,0.125,0.0625],
  )
  '''
  ```

- 第二步滑动窗口进行卷积操作。
  ```
  kernel=3
  radium = kernel//2=1
  #python中的【//】是算术运算符号,表示取整除,它会返回结果的整数部分,例如【print(7//2)】,输出结果为3。
  rows, cols = db.shape
  result2 = copy.deepcopy(db)
  for i in range(radium, rows-radium, 1):
  	for j in range(radium, cols-radium, 1):
  		result2[i, j] = (db[i-radium:i+radium+1, j-radium:j+radium+1] * ka).sum()
  ```

- 另外,经计算发现,borderType=cv2.BORDER_CONSTANT时, 边界填充值为0.
- 参考资料:
  - https://blog.csdn.net/weixin_37804469/article/details/113843829?spm=1001.2101.3001.6650.8&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Edefault-8-113843829-null-114199025.pc_relevant_downloadblacklistv1&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Edefault-8-113843829-null-114199025.pc_relevant_downloadblacklistv1&utm_relevant_index=12
  - https://blog.csdn.net/weixin_41563746/article/details/114199025
  - https://cloud.tencent.com/developer/article/1165877
  - https://docs.opencv.org/2.4/modules/imgproc/doc/filtering.html?highlight=gaussianblur#int%20borderInterpolate(int%20p,%20int%20len,%20int%20borderType)
  - https://docs.opencv.org/3.4/dc/da3/tutorial_copyMakeBorder.html



### 在 OpenCV 中对图像应用`cv2.GaussianBlur()`

我们现在将使用 OpenCV 对图像应用高斯模糊。该技术使用执行加权平均的高斯滤波器，与第一个示例中描述的均匀平均相反。在这种情况下，高斯模糊根据像素值与内核中心的距离对像素值进行加权。离中心较远的像素对加权平均值的影响较小。以下代码使用 OpenCV 中的 GaussianBlur() 函数对图像进行卷积。

```python
GaussianBlur(src, ksize, sigmaX[, dst[, sigmaY[, borderType]]])
#or
dst=cv2.GaussianBlur（src,ksize,sigmaX,sigmaY,borderType）
```

 **`GaussianBlur()`** 函数需要四个输入参数：

- dst是返回值，表示进行高斯滤波后得到的处理结果。
- 第一个参数 `src` 指定要过滤的源图像。 它能够有任意数量的通道，并能对各个通道 独立处理。图像深度应该是CV_8U、CV_16U、CV_16S、CV_32F 或者 CV_64F中的一 种。
- 第二个参数是 `ksize`，它定义了高斯核的大小。 滤波核大小是指在滤波处理过程中其邻域图像的高度和宽度。需要注意，滤波核的值必须是奇数。在这里，我们使用的是 5×5 内核。
- sigmaX 是卷积核在水平方向上（X 轴方向）的标准差，其控制的是权重比例。
- sigmaY是卷积核在垂直方向上（Y轴方向）的标准差。如果将该值设置为0，则只采用sigmaX的值。
- 最后两个参数是 `sigmaX` 和 `sigmaY`，它们都设置为 0。这些是 X（水平）和 Y（垂直）方向上的高斯核标准差。 `sigmaY` 的默认设置为零。如果您只是将 `sigmaX` 设置为零，则标准差是根据内核大小（分别为宽度和高度）计算的。您还可以将每个参数的大小显式设置为大于零的正值。
  - 如果sigmaX和sigmaY都是0，则通过ksize.width和ksize.height计算得到。其中：
    - sigmaX=0.3×[（ksize.width-1）×0.5-1] +0.8      
    - sigmaY=0.3×[（ksize.height-1）×0.5-1]+0.8
- borderType是边界样式，该值决定了以何种方式处理边界。一般情况下，不需要考虑该值，直接采用默认值即可。 在该函数中，sigmaY和borderType是可选参数。sigmaX是必选参数，但是可以将该参数设置为0，让函数自己去计算sigmaX的具体值。
- 函数cv2.GaussianBlur（）的常用形式为：
  **dst=cv2.GaussianBlur（src,ksize,0,0）**

```python
"""
Apply Gaussian blur
"""
# sigmaX is Gaussian Kernel standard deviation 
# ksize is kernel size
gaussian_blur = cv2.GaussianBlur(src=image, ksize=(5,5), \\
sigmaX=0, sigmaY=0)
 
cv2.imshow('Original', image)
cv2.imshow('Gaussian Blurred', gaussian_blur)
     
cv2.waitKey()
cv2.imwrite('gaussian_blur.jpg', gaussian_blur)
cv2.destroyAllWindows()
```

最后，演示 OpenCV 中的双边滤波器（bilateralFilter()），看看它如何在保持清晰边缘的同时平滑图像。耗费计算量大一些

#### LearnOpenCV-用卷积进行图像过滤

[在 OpenCV 中使用卷积进行图像过滤](https://learnopencv.com/image-filtering-using-convolution-in-opencv/#gauss-blur-opencv)

## 建造模型

```python
from tensorflow import keras
from tensorflow.keras import layers
# these are a new feature in TF 2.2
from tensorflow.keras.layers.experimental import preprocessing

model = keras.Sequentail([
    # Input 
    layers.InputLayer(input_shape=[256, 256, 3]),# shape的大小不确定
    # Preprocessing
    preprocessing.RandomContrast(factor=0.10),#色相翻转
    preprocessing.RandomFlip(mode='horizontal'),#左右翻转
    preprocessing.RandomRotation(factor=0.10),#旋转
    # Base
    layers.BatchNormalization(renorm=True),
    #批量归一化应用了一种变换，使平均输出接近 0，输出标准差接近 1。
    #重要的是，批量标准化在训练和推理期间的工作方式不同。
    #训练时，层使用当前批次输入的均值和标准差对其输出进行归一化。
    layers.Conv2D(filters=64, kernel_size=3, padding='same'),
    layers.GaussianNoise(stddev=0.1),
    #高斯噪声 (GS) 对于减轻过度拟合很有用（您可以将其视为随机数据增强的一种形式）。
    #这是作为实值输入的腐败过程的自然选择。
    #因为它是一个正则化层，所以它只在训练时有效。
    layers.Relu(),
    layers.MaxPool2D(),
    # Head
    layers.BatchNormalization(renorm=True),
    layers.Flatten(),
    #layers.GlobalAvgPool2D(),
    layers.Dense(6, activation='relu'),
    layers.Dense(1, activation='sigmoid'),
])
```

### 用预训练模型建造模型

```python
pretrained_base = tf.keras.models.load_model(
    '../input/cv-course-models/cv-course-models/vgg16-pretrained-base',
)
pretrained_base.trainable = False

model = keras.Sequential([
    # Preprocessing
    preprocessing.RandomFlip('horizontal'), # flip(翻转) left-to-right
    preprocessing.RandomContrast(0.5), # contrast change by up to 50% 按p的概率进行随机的图像色相翻转
    # Base
    pretrained_base,
    # Head
    layers.Flatten(),
    layers.Dense(6, activation='relu'),
    layers.Dense(1, activation='sigmoid'),
])
```

## 训练和评估

```python
model.compile(
    optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), 
    loss = 'mean_absolute_error',
    metrics = ['acc']
)
model.fit(train_low_image, train_high_image, epochs = 7, batch_size = 1,
          validation_data = (validation_low_image,validation_high_image))
```

## 预测图像

```python
def plot_images(high,low,predicted):
    plt.figure(figsize=(15,15))
    plt.subplot(1,3,1)
    plt.title('High Image', color = 'green', fontsize = 20)
    plt.imshow(high)
    plt.subplot(1,3,2)
    plt.title('Low Image ', color = 'black', fontsize = 20)
    plt.imshow(low)
    plt.subplot(1,3,3)
    plt.title('Predicted Image ', color = 'Red', fontsize = 20)
    plt.imshow(predicted)
   
    plt.show()

for i in range(1,10):
    
    predicted = np.clip(model.predict(test_low_image[i].reshape(1,SIZE, SIZE,3)),0.0,1.0).reshape(SIZE, SIZE,3)
    plot_images(test_high_image[i],test_low_image[i],predicted)
```

