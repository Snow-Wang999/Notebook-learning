# 9-2-智能图像处理-大作业-文献处理

## 介绍

车辆检测是近年来关键的任务，其主要原因是由于许多跟车辆安全有关的系统中，它是最基础也是最重要的部分。现代城市人口的快速增长增加了对环境可持续性和安全智能技术的需求。在智能交通方面，道路安全是智能城市发展中最关键的问题之一。为了有效减少和避免交通事故以及解决公路交通安全问题，智能汽车不断发展。智能车辆系统通常包括三个部分：环境感知、行为决策、运动规划和控制。环境感知是智能汽车的前提和基础，环境感知的性能直接影响着汽车决策和控制的质量。车辆作为交通环境的主要参与者，是环境感知任务中的重要识别和检测对象。【0-1-2022-智能车辆检测技术】

基于机器视觉的车辆检测方法中，基于先验知识的车辆检测方法原理简单，计算效率高。然而，场景的适应性并不理想，因为车辆的外观很容易受到其他障碍物的干扰。为了提高车辆检测的性能，通常使用各种特征同时检测车辆[10], [15]。此外，先验知识可以与机器学习和深度学习相结合，以提高车辆检测的效率。本文，暂不涉及使用先验知识的车辆检测方法，后续可加以研究。

特征提取和分类器训练是基于机器学习的车辆检测方法的核心。许多车辆特征提取方法从人脸识别和行人检测中吸取了经验教训，例如Haar/Haar类特征、HOG特征和DPM特征，它们在车辆检测中取得了良好的结果。除上述车辆检测特征外，其他特征提取算法也广泛用于车辆检测，如小波、PCA、SIFT、SURF和LBP特征。有时，这些特征的组合可以产生更丰富的车辆检测特征[17]–[19]。本文暂时只研究SIFT特征。

从图像中提取的特征应用于使用分类器识别车辆目标和非车辆目标。用于机器学习的常用分类器包括K近邻（KNN）、支持向量机（SVM）、决策树、随机森林和AdaBoost。分类器的选择需要考虑泛化能力和拟合精度之间的平衡，以及提取特征的维度和数据结构。分类器和特征的不同组合可以导出不同的车辆检测算法，如下表1所示【0-1-2022-智能车辆检测技术】。

![image-20230123170816444](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123170816444.png)

本文在车辆检测工作中，使用了以下方法。首先是基于尺度不变特征变换（SIFT）的特征提取过程，由于该过程识别了一组一致的关键点。然后，该算法旨在通过随机森林（Random Forest）分类器对这些关键点进行分类，即区分属于汽车的点和所有其他点。在程序结束时，通过分析之前被分类为汽车点的关键点来识别场景内的汽车。

> 尺度不变特征转换([Scale](https://so.csdn.net/so/search?q=Scale&spm=1001.2101.3001.7020)-invariant feature transform或SIFT)是一种电脑视觉的算法用来侦测与描述影像中的局部性特征，它在尺度空间中寻找极值点，并提取出其位置、尺度、旋转不变量，此算法由David Lowe在1999年所发表，2004年完善总结。

Lowe[46，48]【0-2-2021-自主车辆感知系统中的行人和车辆检测】提出的SIFT算法是一项了不起的工作，因为该算法能够找到对比例和旋转不变的特征，从而创建一个对部分遮挡、杂波、噪声和照明变化具有鲁棒性的对象识别系统。SIFT算法的缺点是，关键点的重复性在动态对象（例如，人类）中不持久，特征描述符向量的维数相当高，这会影响匹配过程，并且该算法获得专利。现在专利已经过期了。

随机森林算法［16］【3-2-2022-基于高维特征域随机森林的海面小目标检测】将决策树作为基分类器，通过结合 Bagging 集成学习理论和随机子空间方法，改善了决策树的过拟合问题。该算法将多个决策树分类器的分类结果进行投票，从而获得最终分类结果，实现分类器性能的稳定性和高效性。

## 数据集

UIUC Image Database for Car Detection：

**翻译：**

该数据库目前是最常用的研究车辆检测的单尺度数据库，提供原始图像和相关注释文件。数据库包含用于评估目标检测算法的汽车侧视图。汽车图像均为灰度图像，原始PGM格式，总共1328张图片。在训练样本中，有550张阳性样本（汽车图像）和500张阴性样本（非汽车图像）。在单尺度测试样本中，有170张图像，其中包含200个汽车目标，规模与训练图像中的大致相同。在多尺度测试样本中，有108张图像，包含139个不同规模的汽车目标。照片中的车辆都是静止状态的。

Fruit Images for Object Detection：

用于对象检测的不同数据集。训练样本有240个图像。测试样本中有60幅图像。分类目标为苹果，香蕉和橘子。本文使用50张训练图片作为汽车训练阴性样本。使用60张测试图片作为汽车测试阴性样本。

本文新添加的与车辆检测相关性低的训练和测试样本对模型的影响需要在类似的车辆检测的数据集进行进一步验证。

### 数据来源

https://cogcomp.seas.upenn.edu/Data/Car/

[1] Shivani Agarwal, Aatif Awan, and Dan Roth, Learning to detect objects in images via a sparse, part-based representation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 26(11):1475-1490, 2004.

可从此处得到数据集：https://www.heywhale.com/mw/dataset/5e69d076ae2d090037790f1b/content

水果数据集：https://www.kaggle.com/datasets/mbkinaci/fruit-images-for-object-detection/versions/1

视频的分帧图像-车辆检测数据集：https://www.kaggle.com/datasets/sshikamaru/car-object-detection

## 数据预处理

用于检测车辆的SIFT函数描述符是在40×100像素的图像区域上计算的。由于SIFT算法本身具有尺度空间的视觉不变性，即物体的光照变化和物体的空间位置变化对特征点的提取没有任何影响。图像的大小对于SIFT特征提取算法没有任何影响。因此，图像可以是任何大小的。而水果数据集的图像像素为349×349，因此，我们选择车辆图像像素和水果图像像素的中间值。在我们的例子中，选择重置图像的大小为224×224。

![image-20230125203848431](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230125203848431.png)

![image-20230125203923480](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230125203923480.png)

![image-20230125203953150](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230125203953150.png)

![image-20230125204020279](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230125204020279.png)

图像数据集的分割函数如下：

![image-20230125205106595](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230125205106595.png)

图像重置大小功能如下：

![image-20230125210126598](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230125210126598.png)

得到数据集的列表的函数如下：

![image-20230125211537667](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230125211537667.png)![image-20230125211551955](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230125211551955.png)



## sift算法

### 流程

该算法由多个阶段组成，第一步称为“尺度空间极值检测”，它使用高斯函数的差分来检测图像中对尺度和方向不变的潜在关键点。在第二步“关键点定位”中，确定每个关键点的位置和比例，仅选择稳定的关键点。在第三步中，为每个关键点指定一个或多个方向。对关键点周围的区域进行采样，以创建一个方向直方图，该直方图量化了36个区间中关键点的方向，范围为0◦ 至360◦. 关键点的梯度大小用于对36个箱进行投票，仅选择最高峰值和具有最高峰值80%的峰值作为关键点方向。在第三步结束时，每个关键点都应该有一个位置、比例和方向。第四步使用前面步骤中的大小和方向来创建关键描述符向量。最后，通过将新图像的关键点与关键点描述符向量数据库匹配，使用关键描述符向量来识别对象。这是通过使用最佳二进制优先（BBF）排序算法执行最近邻索引和应用霍夫变换（HT）来找到关键点簇来实现的。使用最小二乘法验证新图像是否与数据库中所选图像相关。

### 方法

用sift算法和bow提取训练集的特征，然后用BOVW(Bag of Visual Words) 和K-means聚类算法的方法对特征进行降维，得到词袋聚类特征数据。然后用sift算法与FLANN特征匹配算法来检测训练数据和测试数据，最后得到匹配好的训练集和测试集的词袋聚类特征数据和标签数据。

### 介绍

在物体识别中，提取特征点[22]，[23]是基本的。为了找到准确的良好特征点，有必要选择与其周围相比良好的特征点、拐角和交叉点[24]。在本文中，我们使用SIFT来提取对象的特征点。当检测到一个特定的物体时，即使它们隐藏在光线或物体的阴影中，也很容易被检测到。在本节中，我们简要介绍了SIFT算法。

#### A、 SIFT算法

SIFT是在局部区域上计算的，通常以特征点为中心，但有时也对目标识别任务进行密集采样[25]。

尺度空间极值检测：在所有尺度图像位置上进行联合搜索的第一阶段。它通过使用高斯函数的差分来识别对尺度和方向不变的潜在特征点来有效地实现。

关键点定位：在每个候选位置，一个去尾模型适合于确定位置和规模。关键点的选择基于其稳定性的度量。

方向分配：基于局部图像梯度方向，为每个关键点位置分配一个或多个方向。所有未来的操作都是对已经相对于每个特征的指定方向、比例和位置进行了变换的图像数据执行的，从而为这些变换提供了不变性。

关键点描述符：在每个关键点周围的区域中，以选定的比例测量局部图像梯度。这些被转换为允许显著水平的局部形状失真和照明变化的表示。

在最后一步中，我们可以获得由直方图组成的描述符向量，直方图是根据每个关键点周围窗口中相邻点的梯度和方向计算的。对于使用SIFT特征的大多数应用，这些描述符向量应用于两个感兴趣对象中关键点之间的距离匹配。但是，一些匹配的关键点在其位置上不匹配，必须丢弃这些关键点，以免影响稳定的目标跟踪[26]。

### 1999年

我们希望识别图像尺度空间中的位置，这些位置在图像平移、缩放和旋转方面是不变的，并且受噪声和小失真的影响最小。Lindeberg[8]已经表明，在一些相当普遍的尺度不变性假设下，高斯克尔及其导数是尺度空间分析中唯一可能的平滑克尔。

为了实现旋转不变性和高水平的效率，我们选择了在尺度空间中应用高斯函数差异的最大值和最小值处选择关键位置。这可以通过在每个级别之间重新采样来构建图像金字塔来非常有效地计算。此外，它将关键点定位在高变化的区域和尺度上，使得这些位置对于表征图像特别稳定。Crowley&Parker[4]和Linde-berg[9]先前将高斯在尺度空间中的差异用于其他目的。在下文中，我们描述了一种特别有效和稳定的方法来检测和表征该函数的最大值和最小值。

由于2D高斯函数是可分离的，可以通过在水平和垂直方向上应用两次1D高斯函数来有效地计算其与输入图像的卷积：
$$
g(x)={{1}\over{\sqrt{2\pi}\sigma}}\exp^{-x^2/{2\sigma^2}}
$$
对于关键定位，所有平滑操作都是使用 $\sigma=\sqrt{2}$ 进行的，可以使用具有7个采样点的1D核以足够的精度进行近似。

首先使用 $\sigma=\sqrt{2}$ 将输入图像与高斯函数卷积，得到图像A。然后再次重复该操作，并进一步用 $\sigma=\sqrt{2}$ 进行增量平滑处理，得到新图像B，该图像B现在具有 $\sigma=2$ 的有效平滑。高斯函数的差值是通过从A中减去图像B获得的，结果是两个高斯函数之间的比值为 $2/ \sqrt{2}=\sqrt{2}$。

为了生成下一个金字塔级别，我们使用双线性插值对准备好的平滑图像B进行重采样，每个方向的像素间距为1.5。虽然用相对比例$\sqrt{2}$重新采样似乎更自然，但唯一的限制是采样频率要足够频繁，以检测峰值。1.5间距意味着每个新样本将是4个相邻像素的恒定线性组合。这对于计算和最小化因改变重采样系数而产生的混叠伪影是有效的。

该尺度空间函数的最大值和最小值通过将金字塔中的每个像素与其相邻像素进行比较来确定。首先，将一个像素与金字塔同一级别的8个相邻像素进行比较。如果在这个级别上是最大值或最小值，则在金字塔的下一个最低级别上计算最近的像素位置，同时考虑1.5倍的重采样。如果该像素保持高于（或低于）该最近像素及其8个相邻像素，则对以上级别重复测试。由于大多数像素将在几次比较中消除，因此这种检测的成本很小，比构建金字塔的成本低得多。

如果金字塔的第一级以与输入图像相同的速率采样，则最高的空间频率将被忽略。这是由于初始平滑，这是为鲁棒检测提供峰值分离所需的。因此，在构建金字塔之前，我们使用双耳插值将输入图像扩展2倍。这为典型的512x512像素图像提供了大约1000个关键点，相比之下，没有初始扩展的关键点仅为四分之一。

## 0-综述

### 1. 2022-智能车辆检测技术

（A Review of Vehicle Detection Techniques for Intelligent Vehicles）

1. 背景

   智能汽车是一个多学科综合系统，是最新技术与现代汽车工业相结合的产物。相关研究表明，日益完善的先进驾驶辅助系统和完整的自动驾驶将是有效减少和避免交通事故以及解决公路交通安全问题的根本方法[1]。智能汽车的发展将大大改善未来人们的生活。

   智能车辆系统通常包括三个部分：环境感知、行为决策、运动规划和控制。其中，环境感知是智能汽车的前提和基础，环境感知的性能直接影响着汽车决策和控制的质量。车辆作为交通环境的主要参与者，是环境感知任务中的重要识别和检测对象。近年来，随着计算机技术和传感器硬件的快速发展，许多新的方法和技术被应用于车辆检测。【本文以传感器类型为主线，以检测方法为分类标准，总结了近年来的车辆检测方法，提出了车辆检测的挑战和未来发展方向。】

2. 基于机器视觉的车辆检测方法

   机器视觉是用于车辆检测的最早和最广泛的传感器[2]。这种类型的传感器可以从交通环境中获得丰富的感知信息（纹理、颜色、灰度和语义），并具有表达车辆目标细节的强大能力。由于机器视觉性能的提高和成本的降低，越来越多的公司和研究人员选择了不同类型的摄像头作为智能车辆环境感知的基本解决方案，例如Mobil-eye[3]和Tesla[4]。根据算法的不同原理，基于机器视觉的车辆检测方法有三类：基于先验知识的方法、基于机器学习的方法和基于深度学习的方法。

3. 基于先验知识的方法：车辆底部阴影（Vehicle Bottom Shadow）、尾灯信息（Taillight Information）、边缘特征（Edge Feature）、颜色特征（Color Features）、 对称性（Symmetry）

   基于先验知识的车辆检测方法原理简单，计算效率高。然而，场景的适应性并不理想，因为车辆的外观很容易受到其他障碍物的干扰。为了提高车辆检测的性能，通常使用各种特征同时检测车辆[10]，[15]。此外，先验知识可以与机器学习和深度学习相结合，以提高车辆检测的效率。现有特征可以快速提取图像的车辆ROI，这为深度学习和机器学习搜索潜在车辆区域节省了大量计算时间[6]，[16]。

4. 基于机器学习的机器视觉车辆检测方法

   车辆检测基于机器学习变换，并使用人工设计的特征对车辆的图像信息进行编码。它通过特定的映射方法将图像数据从高维图像空间转换到低维空间。低维特征向量更适合于模型训练。经过反复训练，优化后的模型可用于检测车辆。基于机器学习的车辆检测算法的一般过程如补充材料的图S 2所示。

   特征提取和分类器训练是基于机器学习的车辆检测方法的核心。一种优秀的特征提取方法应该易于提取和区分，并且还应该确保当车辆的姿态和类型发生变化时，所提取的车辆特征保持稳定。

   许多车辆特征提取方法从人脸识别和行人检测中吸取了经验教训，例如Haar/Haar类特征、HOG特征和DPM特征，它们在车辆检测中取得了良好的结果。除上述车辆检测特征外，其他特征提取算法也广泛用于车辆检测，如小波、PCA、SIFT、SURF和LBP特征。有时，这些特征的组合可以产生更丰富的车辆检测特征[17]–[19]。

   从图像中提取的特征应用于使用分类器识别车辆目标和非车辆目标。用于机器学习的常用分类器包括K近邻（KNN）、支持向量机（SVM）、决策树和AdaBoost。分类器的选择需要考虑泛化能力和拟合精度之间的平衡，以及提取特征的维度和数据结构。分类器和特征的不同组合可以导出不同的车辆检测算法，如表I所示。

   基于机器学习的车辆检测方法通常遍历整个图像以提取特征。它可以有效地避免对失踪车辆的检查，但也会造成计算资源的浪费。统计数据显示，图像中超过一半的区域不包含车辆信息[40]。为了提高车辆检测效率，我们可以基于先验知识快速提取车辆ROI，然后使用机器学习方法从ROI中检测车辆，这可以大大提高车辆检测的实时性能。例如，在[41]和[42]中，基于车辆底部阴影从图像中提取车辆ROI，然后使用类Haar特征和AdaBoost分类器从ROI中检测车辆。

![image-20230123170816444](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123170816444.png)

- [38]W.T.Ho、H.W.Lim和Y.H.Tay，“使用温和adaboost和SIFT-SVM的两阶段车牌检测”。第一届亚洲国际会议。信息数据库系统。，2009年4月，第109–114页。

- [39]X.Chen和Q.Meng，“使用SIFT和隐式形状模型从无人机中检测车辆”，载于Proc。IEEE国际会议系统。，赛博人。，2013年10月，第3139–3144页。

3. 弱监督/无监督学习-Weakly Supervised/Unsupervised Learning

   The existing state-of-the-art vehicle detection models based on deep learning are commonly constructed under supervised modes using labeled data with bounding boxes or segmentation masks [293]. However, fully supervised learning has serious limitations, particularly where the collection of bounding box annotations is labor-intensive and where the number of images is large. Besides, the fully supervised model generalization capability is not robust to unseen or untrained objects [294].Weakly supervised or unsupervised learning should be developed to increase the generalization of the model and solve the data absence problem.

   基于深度学习的现有最先进的车辆检测模型通常在监督模式下使用带有边界框或分割掩模的标记数据构建[293]。然而，完全监督的学习具有严重的局限性，特别是在边界框注释的收集是劳动密集型的，并且图像数量很大的情况下。此外，完全监督的模型泛化能力对看不见或未训练的对象并不鲁棒[294]。应开发弱监督或无监督学习，以提高模型的通用性并解决数据缺失问题。

### 2. 2021-自主车辆感知系统中的行人和车辆检测

（Pedestrian and Vehicle Detection in Autonomous Vehicle Perception Systems—A Review）

 INRIA Person Dataset：https://www.payititi.com/opendatasets/show-86.html

有两种主要方法来开发AV感知系统，基于纯视觉或基于传感器融合。本文仅回顾了一种基于视觉的系统，其中单目摄像头安装在车辆仪表板上。AV感知系统必须检测静态和非静态物体，识别静态物体提供的信息，并预测非静态物体的行为。由于篇幅有限，审查将分为三部分。本文是第一篇，将回顾用于检测行人和车辆的计算机视觉技术。随后的综述论文将回顾用于检测和识别交通标志和交通灯的计算机视觉技术，以及用于预测非静态物体行为的技术。

![image-20230123173820205](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123173820205.png)

- 通常目标检测

  AVs应感知静态物体，如停放的汽车、道路工程、道路标志、交通灯等；以及非静态物体，如行人、动物、自行车、大型/中型/小型车辆、摩托车等。在所有这些道路对象中，这项工作集中于行人和车辆，因为前者是最脆弱的对象，后者是与自我车辆交互最多的对象。已经修改了几种通用物体检测算法来检测行人或车辆，因此，本节将回顾最相关的通用物体检测方法，下一节将回顾车辆和行人检测算法。如果读者已经熟悉通用对象检测算法，请参阅第4节或第5节。

  对象检测：检测图像中的单个或多个对象，用边界框包围每个对象并识别它们的位置。

  - 3.1.传统技术

    最著名的传统特征提取技术是尺度不变特征变换（SIFT）[46]、Viola-Jones矩形、Haar-Like-Wavelet、定向梯度直方图（HOG）[47]、边缘方向直方图、光流（运动）、隐式形状模型（ISM）、SHAPELET、自相似Shannels（SSC）、加速上鲁棒特征（SURF）、最大稳定极值区域（MSER）、积分信道特征（ICF）和聚合信道特征（ACF）。用于对象分类的最著名的传统技术是线性支持向量机（SVM）、图形模型、非线性SVM、自适应增强（AdaBoost）、人工神经网络（ANN）和MPL-Boost。从列出的分类器来看，线性SVM是最常用的，因为它需要较少的内存，训练和分类速度快。表3显示了其他学习算法的优点和缺点。

    ![image-20230123174225766](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123174225766.png)

    Lowe[46，48]提出的SIFT算法是一项了不起的工作，因为该算法能够找到对比例和旋转不变的特征，从而创建一个对部分遮挡、杂波、噪声和照明变化具有鲁棒性的对象识别系统。该算法由多个阶段组成，第一步称为“尺度空间极值检测”，它使用高斯函数的差分来检测图像中对尺度和方向不变的潜在关键点。在第二步“关键点定位”中，确定每个关键点的位置和比例，仅选择稳定的关键点。在第三步中，为每个关键点指定一个或多个方向。对关键点周围的区域进行采样，以创建一个方向直方图，该直方图量化了36个区间中关键点的方向，范围为0◦ 至360◦. 关键点的梯度大小用于对36个箱进行投票，仅选择最高峰值和具有最高峰值80%的峰值作为关键点方向。在第三步结束时，每个关键点都应该有一个位置、比例和方向。第四步使用前面步骤中的大小和方向来创建关键描述符向量。最后，通过将新图像的关键点与关键点描述符向量数据库匹配，使用关键描述符向量来识别对象。这是通过使用最佳二进制优先（BBF）排序算法执行最近邻索引和应用霍夫变换（HT）来找到关键点簇来实现的。使用最小二乘法验证新图像是否与数据库中所选图像相关。SIFT算法的缺点是，关键点的重复性在动态对象（例如，人类）中不持久，特征描述符向量的维数相当高，这会影响匹配过程，并且该算法获得专利。现在专利已经过期了。

    > Viola Jones算法是Viola和Jones[49]提出的另一种物体识别算法，他们旨在使用类似Harr的特征提取器识别图像中的人脸。他们的算法主要有四个方面：首先在图像中应用类哈尔特征提取器来选择有区别的特征；其次，使用积分图像算法简化图像表示，从而实现更快的计算；第三，使用AdaBoost学习算法减少了特征的总数；最后，级联分类器被用于拒绝背景信息，并更多地关注可能具有感兴趣对象的区域。该算法被证明非常快，因为它使用700 Mhz Pentium III处理器在0.067秒内处理384×288像素的图像。此外，它实现了高达91.4%的检测率和50次错误检测。虽然该算法速度快，精度高，但训练时间慢，不适合描述一般对象。
    >
    > Dalal和Triggs[47]介绍了HOG算法，旨在检测数字图像中的人类。在HOG算法中，用垂直和水平梯度滤波器处理输入图像，以产生梯度幅度和方向。过滤后的图像首先被划分为8x8像素单元，然后是重叠50%的2×2单元块。创建每个单元（描述符单元）的方向直方图，直方图将计算的梯度方向量化为9个区间，范围为0◦ 至180◦ 并且所计算的幅度被用作每个相应仓的投票。连接属于特定块的每个单元的方向直方图以产生该块的HOG描述符向量。对每个块的HOG描述符向量进行归一化，以考虑照明和对比度的变化。最终HOG描述符是所有归一化块的向量，该向量被馈送到SVM中以对输入图像是人类还是非人进行分类。与Haar Wavelets算法相比，该算法能够减少假阳性结果。HOG算法的缺点是，与SIFT相比，由于密集的网格过程，它需要更多的计算负载，并且当对象被遮挡时，其性能会受到很大影响。
    >
    > Bay等人[50]提出了SURF算法，该算法与SIFT算法有一些相似之处，但作者试图简化它。为了检测图像中的不变特征，作者使用了Hessian斑点检测器和积分图像的基本近似。这种组合提供了更快的计算和良好的精度。Haar小波和积分图像用于方向分配以及创建特征描述符。通过计算输入图像中的特征与数据库中的特征之间的欧几里得距离来实现算法的评估。作者报告说，他们的算法已经超过了当前最先进的算法，如GLOH、SIFT和主成分分析（PCA）-SIFT，实现了85.7%的平均识别率。
    >
    > 前面提到的传统算法的主要缺点是，它们需要手工制作的特征提取器来学习对象的不同描述符。这需要经验丰富的提取器工程师，这很耗时，而且更适合特定的领域系统。

![image-20230123184405147](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123184405147.png)

### 3. 2021-无人地面车辆检测技术

（Review on Vehicle Detection Technology for Unmanned Ground Vehicles）

无人地面车辆（UGV）是集环境感知、位置、导航、路径规划、决策和运动控制于一体的综合智能系统[1]。它结合了计算机科学、数据融合、机器视觉、深度学习等高科技，以满足实现预定目标的实际需求[2]。

在民用应用领域，无人驾驶汽车主要体现在自动驾驶方面。高智能驾驶员模型可以完全或部分取代驾驶员的主动控制[3–5]。此外，带有传感器的UGV可以很容易地充当“探测车”，并执行交通传感，以实现与智能运输系统中其他代理的更好信息共享[6]。因此，它在减少交通事故和缓解交通拥堵方面具有巨大潜力。在军事应用领域，它能够胜任获取情报、监测和侦察、运输和后勤、排雷和简易爆炸装置的放置、提供火力支持、通信转移和战场医疗转移等任务[7]，能够有效地协助部队作战行动。

![image-20230123184522106](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123184522106.png)

![image-20230123183756753](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123183756753.png)

SIFT是指尺度不变特征变换。[160]中提出，通过提取图像中的关键点并附加详细信息来生成特征。在[161]中，基于SIFT提取特征点，并使用隐式结构模型（ISM）提取特征点附近的特征向量，以训练SVM来检测车辆。由于传统SIFT方法计算速度较慢，在[162]中，通过密集SIFT方法提取车辆特征，以实现对远程移动车辆的检测，提高计算效率。在[163]中，设计了颜色不变的“CI-SIFT”，以使其在检测不同颜色的车辆时具有良好的特性。作者首先通过HSV颜色空间识别车身颜色，然后通过CI-SIFT提取特征，最后基于匹配算法实现车辆检测。

![image-20230123180350931](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123180350931.png)

![image-20230123180452720](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123180452720.png)

#### 4. 2006-道路车辆检测

（On-Road Vehicle Detection: A Review）

## 1-车辆检测（英）

#### 1. 2022-基于改进区域卷积神经网络的智能道路**车辆检测**

（Vehicle detection using improved region convolution neural network for accident prevention in smart roads）

现代城市人口的快速增长增加了对环境可持续性和安全智能技术的需求。在智能交通方面，道路安全是智能城市发展中最关键的问题之一[5,13,22]。事故预防[16，17]是道路安全领域的热门话题之一，其目标是找到一种在事故发生之前预测事故的有效机制。计算机视觉和深度学习是模拟人类视觉系统的最新技术。基于计算机视觉和深度学习的几种技术已被开发用于道路安全环境事故预防问题[9,19]。本文遵循这一方向，提出了道路安全环境中事故预防的端到端框架。

物体检测是在给定的图像序列中识别物体的过程。已经提出了几种用于对象检测的深度学习解决方案[3，8，11，12，21]。这项工作针对道路安全环境中事故预防的车辆检测，其动机是物体检测模型在准确检测各种物体方面的有效性。我们认为，实时识别到达的车辆可以减少事故数量，这一点在城市交通稳步增长的情况下尤为重要。

### 2. 2020-基于城市交通场景中道路**车辆检测**的局部二进制模式

（Local binary pattern‑based on‑road vehicle detection in urban traffic scene）

CF-clustering forest

![image-20230123191405824](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123191405824.png)

![image-20230123191717106](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123191717106.png)

![image-20230123191835456](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123191835456.png)

### 3. 2019-基于DFT和DCT域二维HOG特征的车辆检测方案

（A vehicle detection scheme based on two-dimensional HOG features in the DFT and DCT domains）

定向梯度直方图（HOG）通常用作图像中目标检测的特征，因为它们对**照明和环境条件的变化**具有鲁棒性。然而，这些特征对**输入图像分辨率的变化**并不是一成不变的。已经使用了这些特征的2D表示，称为2DHOG特征，因为它保留了相邻像素或单元之间的关系。本文提出了一种新的基于变换域2DHOG特征的车辆检测方案。该方法基于从输入图像中提取2DHOG特征并对其应用2D离散傅里叶或余弦变换。随后是截断过程，通过该截断过程仅保留**低频**系数，称为变换域2DHOG（TD2DHOG）特征。结果表明，从原始分辨率的图像获得的TD2DHOG特征和从同一图像获得的下采样版本在乘法因子内近似相同。然后在我们的方案中利用该特性，使用单个分类器而不是多个分辨率特定的分类器来检测各种分辨率的车辆。实验结果表明，与使用分类器金字塔相比，在所提出的检测方案中使用单个分类器大大降低了训练和存储成本，但提供了类似于使用具有分类器金字塔的TD2DHOG特征所获得的检测精度。此外，所提出的方法提供了与现有技术所提供的检测精度类似或甚至更好的检测精度。

[图像中的高频与低频部分及一些理解](https://zhuanlan.zhihu.com/p/592137494)

1. 首先什么是高频图像，什么是低频图像

- 低频图像就是灰度变化比较小的图像
- 高频图像就是灰度变化比较大的图像

所谓灰度变化比较小的图像就是，内容

所谓灰度变化比较大的图像就是，边缘和纹理，

　边缘：灰度变化较大，比如我穿了一件红色的衣服，北京是白色的，那么，红色衣服与白色背景的边缘是高频的，因为他们的图像变化剧烈，而红色衣服内容他们的变化是低频的，白色背景内容也是低频的，高频，就是变化频率高，变化频率快

　纹理：内部纹理，比如脸上有没有褶子，还有脸上有没有什么斑点，这个都是高频，因为相对于一张平坦无比的大饼脸，一个褶子确实变化很大，所以，这是高频信息

2. 高频和低频图像，对于深度学习来说，学习难度是不一样的，很明显，低频容易学，高频难学

为什么？因为低频图像，在卷积层比对的时候，比如白色的大饼脸，一个简单的卷积，就能比对成功

而对于高频图像，就很复杂，因为线条不一样，那么比对的时候，要生成很多不同的weight,这个不同的weight可能对应于不同形状，比如圆形痦子，三角形痦子，方形痦子，然后看真实图片是哪个，就激活哪个，但是这就需要很多weight，而且肯定比大饼脸难匹配的多，还有可能把头上的发卡当成痦子，所以比较难

3. 面对mse和gan loss的理解

- mse认为高频低频是一样的；
- gan因为是网络，所以更加有针对性；
- gan可以找到更多的纹理细节。

 把原始影像减去低频信息即可得到高频影像信息。

用光学方法消除图像中的高频噪声如下。

1、采用非线性滤波器消除图像中的高频噪声，比如中值滤波器、自适应中值滤波器、半径滤波器等。
2、采用高斯滤波器平滑图像，以改善图像的细节和去除高频噪声。
3、采用自适应Wiener滤波器，它是一种最优滤波器，可以有效地消除图像中的高频噪声。
4、采用傅里叶变换，以消除图像中的高频噪声，并利用低通滤波器进行滤波。

#### 4. 2018-IPOD用于点云的密集点目标检测器

（IPOD: Intensive Point-based Object Detector for Point Cloud）

3D对象检测

3D对象检测大致有三条不同的线。它们是基于体素网格、基于多视图和基于PointNet的方法。

They are voxel-grid based, multi-view based and PointNet based methods.

#### 5. 2016-无人机**探测**和跟踪交通**车辆**

（Detecting and tracking vehicles in traffic by unmanned aerial vehicles）

#### 6. 2015-高分辨率监测图像中工程**车辆的检测**

（Detection of engineering vehicles in high-resolution monitoring images）

#### 7. 2012-一种用于无人机图像中**汽车检测**的**SIFT**-SVM方法

（A SIFT-SVM METHOD FOR DETECTING CARS IN UAV IMAGES）

## 2-SIFT（英）

### 1. 2023-基于**SIFT**和SURF特征提取方法的目标跟踪系统

（An Object Tracking System Based on SIFT and SURF Feature Extraction Methods）

首先，我们展示了不同算法的检测关键点的结果，如图3所示。检测到的关键点的规模不同，因为SURF使用了兴趣点周围的环形区域。对于检测器比较，我们选择了三种类型的视点更改，一种是放大/缩小、旋转和角度更改。SIFT和SURF算法的关键点匹配结果分别如图4和图5所示。红线连接在排名前10的关键点之间。我们观察到关键点匹配的位置差异很大。此外，对于SURF算法，我们可以注意到匹配关键点的精度高于SIFT。

不同算法和不同图像类型的关键点数量结果如图所示。6。横轴显示图像类型。纵轴显示关键点的数量。为了比较每种图像类型的性能，我们考虑了三个测量单位：最大值、中值和最小值。对于缩放和旋转，每个算法的结果几乎相同。对于SIFT，关键点的数量高于SURF。

图7显示了不同算法和不同图像类型的匹配次数结果。我们注意到，在所有情况下，性能差异都很小。每个算法的中值结果几乎相同。

在本文中，我们提出了一种基于SIFT和SURF特征提取方法的目标检测和跟踪系统。从评估结果中，我们观察到**SURF算法匹配关键点的精度高于SIFT。**

在未来的工作中，我们还将考虑用于目标检测和跟踪的其他参数，并进行广泛的实验来评估所提出的系统。

### 2. 2021-二维物体识别：**SIFT**、SURF和ORB特征描述符的比较分析

（2D object recognition: a comparative analysis of SIFT, SURF and ORB feature descriptors）

物体识别是图像处理和计算机视觉领域的一个关键研究领域，它识别图像中的物体并提供适当的标签。本文将三种常用的特征描述算法，即尺度不变特征变换（SIFT）、加速鲁棒特征（SURF）和定向快速旋转BRIEF（ORB）用于目标识别系统的实验工作。本文通过单独确定这三种描述符以及这三种方法的不同组合，对这三种描述进行了比较。使用这些特征提取方法提取的特征量使用特征选择（k均值聚类）和降维方法（局部保持投影）进一步减少。各种分类器，即K近邻、朴素贝叶斯、决策树和随机森林，用于基于对象的相似性对对象进行分类。本文的重点是研究这三种特征提取方法之间的性能比较，特别是当它们的组合在更有效地识别对象时。在本文中，作者对用于2D对象识别的各种特征描述符算法和分类模型进行了比较分析。本文将Caltech-101公共数据集用于实验工作。实验表明，与其他最先进的工作相比，SIFT、SURF和ORB方法与随机森林分类模型的混合实现了最好的结果。在识别准确度、真阳性率（TPR）、假阳性率（FPR）和曲线下面积（AUC）参数方面进行了比较分析。

![image-20230123214005462](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123214005462.png)

![image-20230123224245882](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123224245882.png)

![image-20230123224435307](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123224435307.png)

![image-20230123224454335](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123224454335.png)

![image-20230123224528205](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123224528205.png)

![image-20230123224733806](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123224733806.png)

图2 Caltech-101数据集的特征识别精度

变换（DCT）、局部二进制模式（LBP）、协方差描述符（CD）和小波包变换（WPT），并使用CNN分类器计算平均分类精度。他观察到DCT的特点，因为与其他方法相比，DCT的结果更准确。在他的第二个实验中，他将CNN、FM、MLPNN和NB分类器应用于DCT特征，并证明了朴素贝叶斯分类器以77.2%的准确率优于其他分类器。

![image-20230123225027312](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123225027312.png)

![image-20230123225047647](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123225047647.png)

![image-20230123225155383](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123225155383.png)

![image-20230123225213241](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123225213241.png)

![image-20230123225247775](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123225247775.png)

图5 Caltech-101数据集的特征曲线下面积（AUC）

![image-20230123225324815](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123225324815.png)

图6 Caltech-101数据集的特征5倍交叉验证识别精度

![image-20230123225410821](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123225410821.png)

在本节中，作者介绍了本工作的结论性结果。本文介绍了使用SIFT、SURF、ORB特征描述符以及这些特征描述符的各种组合（使用k-NN、Naive Bayes、决策树和随机森林分类模型）的目标识别结果。实验工作使用公共数据集，即Caltech-101进行。在本文中，基于四个性能评估参数来评估各种技术的性能，即识别准确度、真阳性率（TPR）、假阳性率（FPR）和曲线下面积（AUC）。实验工作表明，当SIFT、SURF和ORB特征描述符的组合用于对象识别系统时，随机森林分类器在所有情况下都表现出更好的性能。此外，还应用5倍交叉验证数据集划分来评估本工作中考虑的所有特征描述符和分类技术的有效性。在未来的工作中，这些特征描述符和这些特征描述符的组合可以用于改进文档图像、医学图像、光谱图像等的识别结果，真阳性率（TPR）、假阳性率（FPR）和曲线下面积（AUC）。实验中使用的分类模型有朴素贝叶斯、K-NN、决策树和随机森林。实验得出结论，与朴素贝叶斯、K-NN和决策树分类器相比，随机森林分类器获得了更准确的结果。这项工作的主要目的是展示SIFT、SURF和ORB特征检测器对名为Caltech-101的公共数据库的对象识别的有效性。

#### 3. 2021（中）-基于结构森林边缘和 **SIFT** 的鲁棒水印算法

用水印对抗对抗性攻击

![image-20230123231616119](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123231616119.png)

![image-20230123231651748](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123231651748.png)

![image-20230123231923316](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123231923316.png)

![image-20230123231945653](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123231945653.png)

### 4. 2020-基于人脸特征区域**SIFT**和SURF描述符的二维人脸识别

（2D-human face recognition using SIFT and SURF descriptors of face’s feature regions）

人脸识别是通过面部图像识别人的过程。它已成为安全和监视应用程序的关键，在任何地方都需要它，包括机构、组织、办公室和社交场所。人脸识别面临许多挑战，包括人脸姿势、年龄、性别、光照和其他可变条件。另一个挑战是这些应用程序的数据库大小通常很小。因此，培训和认可变得困难。人脸识别方法可分为两大类，基于外观的方法和基于特征的方法。在本文中，作者提出了**基于特征**的二维人脸图像处理方法。使用加速鲁棒特征（SURF）和尺度不变特征变换（SIFT）进行特征提取。五个公共数据集，即Yale2B、Face 94、M2VTS、ORL和FERET，用于实验工作。在这项工作中，使用两种分类技术（即决策树和随机森林）对SIFT和SURF特征进行了各种组合。作者报告了SIFT（64个分量）和SURF（32个分量）组合的最大识别准确率为99.7%。

可以通过执行主成分分析来基于特征脸执行人脸识别[28]；拉普拉斯人脸以保存局部信息[11]；fisher面[2]；基于多个子区域的相关滤波人脸[36]；最近邻或子空间方法等等。大量研究人员随后利用了关键的基于特征的技术。最初，Du等人[6]提出了一种基于SURF的特征提取器，该提取器具有尺度和面内旋转不变性。通常，SURF特征检测器具有64个维度。讨论了SURF-64、SURF-128、SIFT-128、SURFdbl-128和SIFTdbl-128的详细结果。Liong等人[19]提出了无监督特征学习技术，以自动从原始像素学习特征表示。作者使用不同的特征字典来表示特征，并为面部区域存储了特征投影矩阵。Huang等人[12]利用小波变换的高频子带来提取面部特征。在FERET、ORL和AR人脸数据库上进行了有效的实验。Vinay等人[30]提出了基于定向快速旋转BRIEF（ORB）的人脸识别技术，该技术被认为是一种比现有技术精度更高的鲁棒性人脸识别技术。Carro等人[3]分析了加速鲁棒特征（SURF）是公认的最有效的特征。使用矩阵估计方法（RANSAC）。所提出的方法即使在部分闭塞的情况下也能执行。Klemm等人[15]提出了一种基于关键点的人脸检测技术。对使用基于全局特征（特征面）的技术以及基于局部（LBP、Gabor滤波器）特征的技术进行了性能比较。Hassner等人[9]提出了一种新的基于模板的人脸识别。该算法旨在提高精度，降低计算和存储成本。Werghi等人[35]提出了一种使用形状和纹理局部二进制模式（LBP）进行3D人脸识别的集成方法。首先，从人脸网格计算LBP，然后构建描述网格。Naik和Panda[22]提出了一种自适应布谷鸟搜索算法，以更快的速度改进目标函数值。使用23个标准基准测试函数对提出的算法进行了验证。测试了三个标准人脸数据库，即Yale2B、ORL和FERET，以获得准确的识别率。Wen等人[34]提出了基于进化神经网络（CNN）的新监督信号，称为中心丢失，用于人脸识别任务。中心损失同时学习每个类的深度特征的中心，并惩罚深度特征与其对应的类中心之间的距离。标记的野外人脸（LFW）、YouTube人脸（YTF）和MegaFace挑战数据集用于实验。

Guntupalli和Gobbini[8]强调了学习和与其他大脑区域的互动对识别熟悉面孔的贡献。Lu等人[21]提出了从不同姿态、照明、表情和分辨率进行人脸识别的特征和字典学习技术。Karczmarek等人[13]提出了基于链码的局部描述符（CCBLD）的扩展。有人建议使用连锁代码来制作一袋视觉单词。Chhabra等人[5]提出了一种基于内容的图像检索（CBIR）系统，用于从人脸中提取特征。使用了定向快速旋转BRIEF（ORB）和尺度不变特征变换（SIFT）。使用决策树、随机森林和MLP对提出的特征进行分类。Li等人[18]解释了多种类型特征的集成对于准确和稳健的人脸识别的重要性。提出了一种基于卷积神经网络的彩色二维主成分分析方法。

Wang[31]研究了年龄和性别对面部识别的影响。使用深度学习方法对面部特征进行分类。平均识别率为83.73%。Ranjan等人[25]研究了各种人脸识别协变量，如姿势、照明、表情和图像分辨率。该方法研究了种族、年龄和性别等不可控协变量对人脸识别的影响。123

![image-20230123232845254](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123232845254.png)

人脸识别有三个基本步骤：人脸检测、特征提取和人脸匹配，如图1所示。这些步骤只是在识别人脸时对人类行为的模拟。无论何时，作为人类，我们要识别一张脸，实际上我们会无意识地遵循这些步骤。**人脸检测是人脸识别的主要步骤。**在该步骤中，系统需要识别给定图像/场景中的面部（如果有的话）。它旨在通过预处理和从输入图像/场景中提取面部图像来识别面部。人脸检测需要对图像进行预处理，即人脸边缘检测、分割和定位。边缘检测用于在图像中突出显示面部的边界和其他特征。然后，使用分割和定位来从图像的其余部分定位和分割高亮显示的面部边界。在获得感兴趣的区域（即，面部补丁）之后；随后是面部区域的特征提取和表示。特征提取的目的是将人脸贴片转换为具有固定维度的向量或具有相应位置的一组特征点。目标是提取和表示人脸图像的固有属性。提取的特征可以是视觉特征、统计像素特征、变换系数特征或代数特征。然后，将获得的面部固有特征与现有面部固有特征数据库进行匹配，以执行面部匹配/分类。特征提取是所提出的人脸识别系统的最重要阶段。在此阶段，提取重要特征用于人脸识别。本文考虑了两种特征提取技术，即SURF和SIFT，用于人脸识别。以下小节将简要讨论这些技术。

#### 提出的算法

输入：查询图像

步骤1：使用SURF和SIFT从训练图像中提取特征描述符，如所讨论的

步骤2：使用K-means聚类算法生成128个聚类。计算每个簇的平均值以获得每个描述符的128维特征向量

步骤3：使用LPP降维算法将128个单元的特征向量降为32和64个分量

步骤4：将两个特征向量（即。，SURF和SIFT，并将组合的特征向量存储在数据库中

步骤5：使用SURF和SIFT特征向量的组合来训练所提出的系统，以获得分类模型

步骤6：通过插入查询对象图像来测试训练的分类器模型，并提取被质疑图像的SURF和SEFT特征

步骤7：预测查询对象数据特征和使用模型分类器训练数据集

![image-20230123233153927](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123233153927.png)

![image-20230123233208667](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123233208667.png)

![image-20230123233222093](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123233222093.png)

![image-20230123233233424](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123233233424.png)

![image-20230123233246748](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123233246748.png)

![image-20230123233355379](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123233355379.png)

在这篇研究论文中，作者提出了一种有效而准确的人脸检测算法，该算法基于SURF和SIFT算法的特征提取的集成。在FACE 94、Yale2B、ORL、FERET和M2VTS数据集上的实验结果表明，所提出的方法是有效和稳健的。分类器性能基于准确度、真阳性率、假阳性率和曲线下面积来确定。所提出的研究的关键特征是人脸检测具有较高的准确性和较低的假阳性率。此外，发现该算法在计算上是有效的。两个分类器，即决策树和随机森林，用于实验结果，以验证所提出的系统的性能。利用所提出的基于特征的模型，对各种人脸数据集获得了比较或更好的结果。

### 5. 2020-一种基于Shi-Tomasi角点检测算法的目标识别方法

（An efficient technique for object recognition using Shi-Tomasi corner detection algorithm）——角点检测结合**SIFT**

一种有效的特征检测算法和图像分类是计算机视觉系统中非常关键的任务。有各种最先进的特征检测器和描述符可用于对象识别任务。在本文中，作者比较了Shi-Tomasi角检测器与SIFT和SURF特征描述符的性能，并结合SIFT和SURF特征描述符评估了Shi-Tamasi的性能。为了使计算速度更快，作者通过应用局部保持投影方法，在所有情况下都减小了计算的特征的大小。使用这些算法提取的特征进一步使用各种分类器（如K-NN、决策树和随机森林）进行分类。对于实验工作，本文考虑了一个公共数据集，即Caltech-101图像数据集。该数据集由101个对象类组成。这些类还包含许多图像。使用Shi-Tomasi、SIFT和SURF特征的组合，作者使用随机森林、决策树和K-NN分类器分别获得了85.9%、80.8%和74.8%的识别准确率。本文还计算了所有病例的真阳性率、假阳性率和曲线下面积。最后，作者应用**自适应增强方法**提高了识别精度。作者报告了使用随机森林分类器的自适应增强以及Shi-Tomasi、SIFT和SURF特征的组合，将识别准确率提高了86.4%。

作者使用K-NN，决策树和随机森林分类器描述了所有这三个特征检测器和描述符的单独结果。基于实验工作，作者注意到，与SIFT和SURF描述符相比，单独的Shi-Tomasi角检测器算法的性能更好。但是，当他们将这三种算法结合在一起时，他们的结果得到了更大的改善。使用公共数据集（即Caltech 101图像数据集）进行实验。该数据集是101个对象类的集合，每个类包含40–800个图像。这是一个非常大的数据库，有9000多张图片。作者已经考虑了每节课中80%的图像作为训练，每节课剩余的20%用于测试。Shi-Tomasi、SIFT和SURF输出了大量需要大量内存的特征集。因此，在SIFT和SURF描述符算法以及这三种算法上的局部保持投影（LPP）之后，使用了k均值聚类算法。使用k均值聚类和LPP使得特征数据库的大小变小。使用k-NN、决策树和随机森林算法对所有三种特征检测算法提取的特征进行进一步分类。使用k-NN、决策树和随机森林分类器，识别准确率分别达到74.7%、80.8%和85.8%。在本文中，作者还介绍了真阳性率（TPR）、假阳性率（FPR）和曲线下面积（AUC）。实验结果在第节中讨论。6.作者观察到，与其他分类器相比，随机森林分类器的性能优于85.8%（TPR）、0.2%（FPR）和99.7%（AUC）。自适应增强和自举聚合方案也被应用于提高准确率，这使得识别准确率和真阳性率略有提高。本文总结为7个部分。第2节介绍了与对象识别相关的先前工作。在第。3，作者简要描述了Shi-Tomasi角检测器和尺度不变特征变换（SIFT）以及加速鲁棒特征（SURF）特征描述符。第4节将简要介绍我们实验中使用的各种分类器。第5节将详细介绍本文中提出的工作以及用于改进目标识别结果的其他方法。在第。6，作者讨论了实验结果。第7节将介绍这项工作得出的结论。

引导聚合（Bootstrap aggregation）是一种机器学习集成方法，用于提高使用决策树计算的性能。决策树具有很高的方差，就像在训练数据中有一些变化一样，生成的决策树将非常不同。使用自举聚合方法来减少这些算法的方差。引导聚合方法还避免了数据的过度拟合。多数投票方案或平均值用于组合各种分类器的结果。自举聚合的结果将为弱分类器（如决策树）提供更高的精度，但不会为强分类器（如Naııve Bayes）提供更准确的精度。

![image-20230123234520847](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123234520847.png)

![image-20230123234555179](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123234555179.png)

![image-20230123234721616](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123234721616.png)

![image-20230123234848363](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123234848363.png)

![image-20230123234923492](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123234923492.png)

为了提高精度，作者还应用了自适应升压方案（adaptive boosting scheme）和自举聚合方案（ootstrap aggregation），并在应用自适应升压后得到了一些改进。

![image-20230123235223197](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123235223197.png)

本文提出了一种特征检测器和描述符的组合，使目标识别任务更容易、更快。该实验在大型公共数据集Caltech101上实现，该数据集在对象识别问题中仍然是一个极具挑战性的数据集。通过用各种分类器【即K-NN、决策树和随机森林】分类【使用Shi-Tomasi、SIFT和SURF提取的】特征。为了减少特征的大小，还使用了k均值聚类和局部保持投影（LPP）。这种方法提高了对象识别过程的速度。自适应增强和自举聚合用于提高对象识别的性能。80%的图像用于训练阶段，其余20%用于测试。在三种分类器中，使用自适应增强方案，随机森林分类器以85.9%的识别准确率和86.4%的识别准确度优于其他分类器。该方法可用于图像处理和计算机视觉领域的其他不同应用。

### 6. 2020-基于**SIFT**和K-Means算法的图像处理结核病检测体系结构

（Tuberculosis Detection Architecture with Image Processing using the SIFT and K-Means Algorithm）

![image-20230124114658782](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230124114658782.png)

![image-20230124114711546](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230124114711546.png)

![image-20230124115406062](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230124115406062.png)

测试使用准确性和召回度量作为图6中的评估度量，其中：

- VP：真阳性（诊断为患病的X光片）。
- FP：假阳性（诊断为阳性的健康射线照片）
- FN：假阴性（诊断为健康的病X光片）
- VP：真阴性（诊断为健康的健康X光片）。

**ROC曲线**：

我们展示了ROC曲线图，显示了真阳性与假阳性的比率，在这种情况下，我们可以看到数据集中了真阳性，这表明该模型分类良好，我们接受该模型。

**准确度和召回**：

我们还使用准确度、准确度和收回度量对我们的架构进行了评估，已经进行了9次测试，在每个测试中，我们计算了准确度和回收率，如下表所示。

我们计算的平均精度为90.302%，平均精度为89.07%，这反映了实验中不同测量值正确分类的接近程度。同样，我们计算了表示灵敏度的召回94.44%度量的平均值。

从所获得的结果中，我们可以看到召回率很高，我们可以观察到结果中假阴性的减少，这对所提出的建议是非常有利的。

另一方面，所获得的精度是一个可接受的值，这是真阳性和真阴性的表示，必须考虑到从中推断出的召回指示符中存在较低的假阴性率。据解释，错误诊断的很大一部分是假阳性（被诊断为患病的健康患者），这减少了错误的负面影响。

![image-20230124115727896](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230124115727896.png)

![image-20230124115742800](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230124115742800.png)

![image-20230124115754050](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230124115754050.png)

### 7. 2020-基于ORB和**SIFT**特征的基于内容的图像检索系统

（Content-based image retrieval system using ORB and SIFT features）

特征提取

CBIR系统最重要的部分是提取图像的有意义的特征。在本工作中，作者考虑了两种特征提取技术，即SIFT和ORB，用于提取图像的描述符。之后，应用K-means聚类算法使用描述符向量生成K个聚类，并使用LPP降低特征向量的维数。

![image-20230124113715315](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230124113715315.png)

利用局部保持投影（LPP）将高维空间缩小到低维空间以存储信息。LPP查看有关信息索引的邻域数据，并在LPP中查看具有类似类位置的任何信息。LPP意味着保留所需的信息并删除不需要的数据。PCA保存的数据信息比LPP少。降维LPP分三个阶段工作，如下所示：

![image-20230124114245529](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230124114245529.png)

![image-20230124114205959](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230124114205959.png)

![image-20230124114524025](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230124114524025.png)

### 8. 2019-使用**SIFT**和ORB特征检测器改进目标识别结果

（Improved object recognition results using SIFT and ORB feature detector）

#### Proposed algorithm-建议的算法

输入：查询图像。

步骤1：使用ORB和SIFT特征提取方法从训练数据集的图像中提取特征描述符。

步骤2：使用K-means聚类算法为每个描述符数组生成64个聚类。然后，计算每个聚类的平均值，以获得每个描述符的64维特征向量。

步骤3：使用LPP降维算法将64个单元的特征向量降为8、16和32个分量。

步骤4：整合两个特征向量，即ORB和SIFT，并将组合的特征向量存储在数据库中。

步骤5：使用ORB和SIFT特征向量的组合训练所提出的系统以获得分类器模型。

步骤6：通过输入查询对象图像来测试训练的分类器模型，并提取被查询图像的ORB和SIFT特征。

步骤7：使用模型分类器预测查询对象数据特征和训练数据集之间的相似度。

> Input: Query Image.
> Step 1: Extract a feature descriptor from images of training dataset using ORB and SIFT
> feature extracting methods.
> Step 2: Use K-means clustering algorithm to generate 64 clusters, for every descriptor array.
> Then, compute the mean of every cluster to obtain a 64 dimensional feature vector
> for every descriptor.
> Step 3: Use LPP dimensionality reduction algorithm to reduce the feature vectors of 64 units
> into 8, 16 and 32 components.
> Step 4: Integrate the both feature vectors i.e. ORB and SIFT and store the combined feature
> vector in database.
> Step 5: Train the proposed system using a combination of ORB and SIFT feature vectors to
> obtain the classifier model.
> Step 6: Test the trained classifier model by inputting the query object image and extract the
> ORB and SIFT features of a questioned image.
> Step 7: Predict the similarity between query object data features and trained dataset using the
> model classifier.

![image-20230124000330862](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230124000330862.png)

比较特征的数量

![image-20230124000156113](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230124000156113.png)

### 9. 2019-低分辨率图像中保留SIFT关键点的多尺度梯度图像超分辨率 

（Multi-Scale Gradient Image Super-Resolution for Preserving SIFT Key Points
in Low-Resolution Images）

低分辨率图像对各种监视和导航应用中的各种对象识别问题提出了挑战。近年来，深度学习在像素域峰值信噪比（PSNR）/均方误差（MSE）方面提高了图像超分辨率（SR）的技术水平。受深度卷积神经网络在一般图像SR任务中的最新进展启发，我们通过使用不同尺度的多个卷积神经网络学习超分辨率梯度图像，开发了一种计算机视觉任务驱动的图像SR解决方案。在多个尺度上恢复超分辨率梯度图像，使系统能够恢复更多对高级视觉任务有用的信息，而不仅仅是像素域中的SR。特别地，我们提出了一种残差学习框架来在高斯差分（DOG）域中执行图像SR。然后，训练后的残差网络模型被用于驱动广泛采用的图像识别关键点算法，即SIFT检测和匹配。实验结果表明，与像素域图像SR解决方案的现有技术相比，所提出的方法可以显著提高SIFT关键点的重复性。

在现代，图像识别的一个关键挑战在于处理低分辨率图像，特别是在军事和监视应用中。此外，识别远处物体的能力对于国防部（DoD）用例中的许多目标识别问题具有重要价值，如反无人飞行器系统（UAS）应用。UAS应用中的DDDAS（动态数据驱动应用系统）是一种新的范例，通过该范例，应用系统的计算和仪表方面被动态集成到具有反馈的控制回路中[1]。数据被动态地合并到应用程序的执行模型中，反过来，执行模型可以控制插入。DDDAS寻求推进的挑战包括数据建模、上下文处理和内容应用。数据需要在预处理时收集，以确定其固有信息是否与上下文匹配。其中一些例子包括车辆跟踪中的杂波抑制、传感器配准和混淆分析[1]。因此，需要准确识别拍摄的图像。在这种情况下，最流行的解决方案之一是图像超分辨率。图像超分辨率是图像处理领域最重要的计算机视觉与模式识别研究领域之一。

超分辨率[2]意味着找到从低分辨率（LR）图像到高分辨率（HR）图像的映射。

在单帧超分辨率（SISR）的情况下，对于单个图像，增加了像素数量，以便超分辨率图像在视觉上看起来更好，并且在识别时更有效。超分辨率有多种方法。双三次和双线性上尺度方法[3]对于已经被广泛使用的超分辨率非常流行。此外，基于稀疏编码表示的SR方法[4,5]大大提高了分辨率。

在许多识别任务中，梯度图像是从像素图像导出的重要信息。为了定义，梯度图像通常指图像强度或颜色方向的变化。已经使用图像的梯度进行了许多关于图像识别的工作。

在[13]中，哈里斯检测器（*Harris Detector*）用于找出图像的**边缘**和提取**角点**，以及发现图像的推断特征。

在[14]中，高斯拉普拉斯算子（*Laplacian of Gaussian*）用于**斑点**检测。

在[15]中，使用SIFT特征（*SIFT feature detection*）检测，在从DoG图像集计算最大值和最小值后发现**局部特征**。

在识别中，从对象中提取关键点，以提供用于识别对象的特征描述。因此，重要的是要记住，提取的特征应该能够在**尺度、噪声和照明变化**的情况下使用。SIFT可以处理这些变化，这使得SIFT成为特征提取的理想方法。关于特征保存的研究很少。在[16]中，引入了一种用于保留局部特征的可视化查询压缩。在这里，他们经历了视觉关键点压缩中的一种新方法，该方法使用子空间来优化保持关键点特征匹配特性，而不是重建性能。此外，SIFT特征保存在图像识别中起着重要作用。关于SIFT特征在提高图像识别精度方面的作用，有很多研究。在[17，18]中，解释了SIFT特征在图像识别中的应用。在我们提议的方法，我们有动机保留这些关键的SIFT点，以便它能够在识别低分辨率图像方面卓有成效。

我们在本文中提出的方法不是端到端系统。相反，它是一个产生**SIFT重复性的超分辨网络**。因此，我们提出的方法的目标是产生SIFT重复性，并显示这些SIFT点如何有助于更好的识别。为了实现产生SIFT重复性以保留更多特征的目标，我们将在梯度域中进行超分辨率。在[19]中，小规模测试了SIFT重复性。在本文中，我们使用多样化的数据集在更大范围内测试了我们的方法。

提高低分辨率和高质量的图像识别性能在现实世界的视觉、导航和监视应用中具有很多价值。在这项工作中，我们开发了一个用于多尺度梯度图像超分辨率的深度学习框架。这改进了超分辨率网络自由度（DoF），与最先进的像素域超分辨率解决方案相比，它允许不同比例的梯度图像由不同的网络进行超分辨率，在低分辨率关键点检测和重复性方面具有良好的性能增益。接下来，我们将优化网络结构，包括像U-Net这样的新架构，并研究在噪声和低光条件下的梯度图像增强，从而为低分辨率/高质量图像识别提供全套解决方案。

未来，我们将进一步扩展该框架，以对抗图像通信中的量化和通信损失，并使用任务集成的深度学习解决方案执行后续视觉任务。

### 10. 2016（中）-基于空间金字塔和特征集成的智能机器人**目标检测**算法

![image-20230124145316989](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230124145316989.png)

![image-20230124145705338](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230124145705338.png)

![image-20230124145725125](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230124145725125.png)

![image-20230124145735732](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230124145735732.png)

<img src="C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123014629278.png" alt="image-20230123014629278"  />

<img src="C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123014649285.png" alt="image-20230123014649285"  />

![image-20230124151353272](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230124151353272.png)

### 11. 1999-基于局部尺度不变特征的目标识别

SIFT特征在很大程度上不受尺度、照明和局部7仿射失真的影响，从而改进了先前的方法。典型图像中的大量特征允许在杂乱图像中的部分遮挡下进行鲁棒识别。与仅依赖于索引的方法相比，求解仿射模型参数的最后阶段允许更精确的验证和姿态确定。

进一步研究的一个重要领域是从多个视图构建模型，以表示目标的3D结构。这将具有进一步的优点，即可以将来自多个查看条件的关键字组合到单个模型中，从而增加在新视图中找到匹配的概率。模型可以是基于运动解决方案的结构的真实3D表示，或者可以通过自动聚类和插值来表示外观空间（Pope&Lowe[17]）。后一种方法的一个优点是它还可以模拟非刚性变形。

通过添加新的SIFT特征类型以结合颜色、纹理和边缘分组以及不同的特征大小和偏移，可以进一步提高识别性能。在背景杂波可能干扰其他特征的对象边界处，可以进行局部图形-背景区分的比例不变边缘分组将特别有用。索引和验证框架允许将所有类型的比例和旋转不变特征合并到单个模型表示中。通过检测许多不同的特征类型并依靠索引和聚类来选择在特定环境中最有用的特征类型，可以实现最大的鲁棒性。

## 3-caj（中）

### 1. 2022-集成**SIFT**算法与检测模型优化的UAV影像匹配方法_高莎

![image-20230124121840688](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230124121840688.png)

无人机影像匹配是无人机影响后期处理的关键步骤,直接影响后期三维重建与特征信息提取的精度。针对高原山地复杂地形低空无人机影像存在区域变形严重,高差大,影像遮挡严重,特征点不明显以及数据量大等问题,探讨研究了面向高原山地复杂地形无人机影像如何快速匹配又能保证正确率的问题。

总结本研究主要工作及初步成果包括:

①针对研究区区域变形严重,高差大,影像遮挡特征不明显等问题,利用主流的SIFT, SURF, BRISK, ORB 和 KAZE 算法进行试验研究,通过综合对比分析,可以发现基于SIFT+算法的影像匹配在面向山区复杂地形区域时可以很好地发挥其优势,无论在特征点提取数量还是在匹配正确率方面都较其他4种匹配算法精度高,可靠性强。

②通过改进影像匹配算法,用“马氏距离”位置匹配替换传统欧式距离匹配并结合NNDR模型对匹配点对进行相似度检测,实现特征点的二次筛选,实验结果表明 SIFT+算法在针对特征点对的二次筛选时不仅可靠性强,而且缩短了时间成本,提高了数据处理效率。

③为进一步提高影像匹配精度,需要剔除错误匹配特征点对,结合 RANSAC算法引入 RMSE 对影像匹配结果进行约束,当 RMSE值超过预设阈值时候,则需要剔除影像匹配中的残差最大点,该方法不仅匹配正确率相对较高,而且精配准阶段通过RMSE约束条件下,配准精度可以达到亚像素精度。 

### 2. 2022-基于高维特征域**随机森林**的海面小**目标检测**_施赛楠

#### 随机森林模型

随机森林算法［16］将决策树作为基分类器，通过结合 Bagging 集成学习理论和随机子空间方法，改善了决策树的过拟合问题。该算法将多个决策树分类器的分类结果进行投票，从而获得最终分类结果，实现分类器性能的稳定性和高效性。

由于人工提取特征数目的有限性，文中只引入分裂因子获得随机特性，如图 1 所示。首先，假设两类训练样本各 K 个，海杂波样本标记为 0，含目标回波样本标记为 1。设置 M 棵决策树，所有决策树的深度为 D。其次，在模型训练过程中，从两类训练样本中随机均匀抽取 M 个样本子集，记为 K1，K2，…，KM，每个样本子集的数目为［2K×α］，其中，［］表示取整。然后，这些子集作为 M 棵决策树的输入，独立获得决策树的分类结果。最后，根据“少数服从多数”的准则获得最终分类结果。同时，随机森林做了预剪枝处理，降低模型过拟合的风险以及减少计算代价。

![image-20230124125018260](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230124125018260.png)

![image-20230124125045609](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230124125045609.png)

![image-20230124125853264](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230124125853264.png)

### 3. 2022-基于**随机森林**的雷达**目标**多维特征**检测**方法_欧阳可赛

随机森林方法简介

集成学习( Ensemble Learning) 是机器学习领域中一种将多个学习器高效结合的方法［14－15］。相较于基于单个学习器的机器学习方法，集成学习能够集成较弱的基学习器，形成可以精确预测的强学习器，从而提升模型的泛化能力。

随机森林是一种典型的集成学习算法，其是集成学习中 Bagging 集成策略中最为实用的算法之一［13］。相较于其他 Bagging 方法，随机森林的不同之处在于其引入了随机特征选择，即在决策树选择分割点时，随机森林会随机选择一个特征子集完成传统的分割点选择。一个典型的随机森林算法通过随机数据采样形成不同的分支，并最终集成各个分支的预测结果实现对目标的准确分类。

![image-20230124125630632](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230124125630632.png)

![image-20230124125706018](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230124125706018.png)

### 4. 2018-基于深度优先**随机森林**分类器的**目标检测**_马娟娟

广度优先方法是随机森林分类器常用的训练方式。例如，Schulter 等在目标检测时提出了联合分类回归森林，树的训练方式是广度优先方法[11]。广度优先方法在多核 CPU 和 GPU 系统容易实现并行化运算。

本文提出了深度优先方法递归地训练随机森林分类器，将其应用于无人机感知与规避系统的目标检测，从机载视觉传感器获取的图像中检测近距离目标。深度优先方法训练随机森林分类器，每次递归过程只分裂一个节点，节省内存。在 SenseAndAvoid 数据集测试了算法性能。实验表明，大量样本训练随机森林分类器，深度优先方法生成的树能抑制欠拟合，提高了随机森林分类器的泛化能力和目标检测的准确性。

![image-20230124130741255](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230124130741255.png)

虽然广度优先方法在多核CPU和GPU系统容易实 现并行化运算，但是如果训练样本太大，随着树的层数 增加，广度优先方法训练随机森林分类器会导致欠拟合。相反，深度优先方法每次仅训练一个节点，节省内存，能有效抑制欠拟合，以提高随机森林分类器的泛化能力。

![image-20230124130913589](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230124130913589.png)

![image-20230124130944703](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230124130944703.png)

![image-20230124131022577](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230124131022577.png)

3.4  随机森林分类器

### 5. 2015-基于**随机森林**的精确**目标检测**方法_向涛

本文首先利用多维图像块特征和 Boosting 算法改进传统随机森林中树的构建过程，通过这一改进，使得节点的每次划分相比于单值比较更加符合目标图像的结构特性，同时还使蓝样本得到更多关注。其次，本文**基于目标图像原始长宽比对传统随机森林的输入输出空间进行扩展**，使得该模型不仅可以用于分类，还可以有效预测检测框的最优长宽比，以提高检测窗与真实目标区域的重叠率。实验结果表明，本文方法在不增加时间开销的情况下，显著提高了目标检测的精确性。

### 6. 2015-可见光海面**目标检测**的结构**随机森林**方法_雷琴

基于先验的目标检测算法

![image-20230124141353842](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230124141353842.png)



## 4-pdf（中）

### 1. 2020-基于深度**森林**的多级特征融合SAR目标识别

![image-20230124141538416](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230124141538416.png)

![image-20230124141600327](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230124141600327.png)

Dense-SIFT特征的关键点提取是通过使用**窗口滑动**的方式对图像中的网格点进行密集采样而得
到的，提取示意图如图2所示。用窗口尺寸的切片窗口从图像左上角的初始位置以滑动步长开
始滑动，之后按此方法扫描直到窗口到达图像右下角位置，对每个小窗口的中心点计算一个SIFT特
征，所有窗口的SIFT特征组合起来，即构成了该图像的密集SIFT特征。提取Dense-SIFT特征的具
体流程如表1所示。

[Sift VS Dense Sift](https://blog.csdn.net/historycomputer/article/details/59541387)

[计算机视觉学习——Knn算法 稠密SIFT(Dense-sift) 图像分类（手势识别）](https://blog.csdn.net/weixin_42424674/article/details/90343538)

当研究目标是对同样的物体或者场景寻找对应关系（correspondence）时，Sparse SIFT更好。而研究目标是图像表示或者场景理解时，Dense SIFT更好，因为即使密集采样的区域不能够被准确匹配，这块区域也包含了表达图像内容的信息。

​    Sparse SIFT还有一个重要优点就是，输出的特征的结构是固定的（特征点数量稳定）。这对于spatial configuration的建模十分重要[3]。

​    顺便废话一句，CNN的卷积层的输出，可以作为一个新的Dense Feature，用来代替人工设计的Dense Feature如HOG map啦。111



![image-20230124140115610](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230124140115610.png)

![image-20230124140134703](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230124140134703.png)

### 

#### 2. 2019-基于改进Grassberger熵**随机森林**分类器的**目标检测**

对Grassberger熵进行改进,采用改进的Grassberger熵计算信息增益,选择分裂节点的最优分裂属性训练随机森林分类器,利用经过训练的随机森林分类器预测选择性搜索生成的子窗口是否包含目标.对每个训练样本及子窗口提取1个归一化梯度幅值、3个LUV颜色通道和6个梯度方向直方图的特征.在SenseAndAvoid数据集上测试了所提方法的性能,取得了73.2％的平均检测准确率.结果 表明:安全包络范围内的平均检测准确率高于98％.利用改进的Grassberger熵计算信息增益,能提高目标检测的准确率.

![image-20230124144124704](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230124144124704.png)

图1. 节点分裂算法

### 3. 2018-基于**随机森林**的无人机检测方法

![image-20230124142515428](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230124142515428.png)

本文基于无人机**运动小目标的运动特性和外观特性**，提出了一种在复杂背景下鲁棒的无人机等弱小目标检测算法。该算法通过综合无人机小目标的运动特性、图像局部对比度、目标图像灰度值的相关性，进而大幅提升了检测的准确率。本文方法对无人机的确认是**基于目标的相对运动**，其前提是：当摄像头连续监控某天区时，无人机要进入视场，一定会存在运动。今后，还可以进一步研究在单帧图像内对于无人机小目标的检测以提高检测算法的召回率。

### 4. 2014-基于**随机森林**和支持向量机的快速行人检测算法

由于图像一般包含较多的背景，因此对于可见光图像，最好也能快速地消除图像中的背景。在文献［8 - 9］中，FPDW及其改进算子达到了每秒近百帧的检测速率，其重要原因就是利用**深度信息快速地消除了图像背景**，获得了至少 20 倍的速度提升（ 其次得益于相对复杂的训练方式和硬件性能），同
时也大大降低了误检的可能。

以此为启发，本文提出一种利用**随机森林作为分类器的背景消除算法**。随机森林是机器学习领域的一种重要分类方法，其主要特点是随机的特征选择，组合决定树以降低单个决定树的分类不确定性。传统的随机森林及其拓展的霍夫森林在目标检测和识别算法中得到了很多应用，被证明具有很好的分类性能，但直接用来检测行人同样比较耗时［4，10］。而本文则采用一定简化的随机森林，获得一个相对粗略的分类结果。确定感兴趣区域（ ROI）后，再作进一步的 SVM 检测。事实证明，这样可有效地发挥二者各自的优势。


![image-20230124142855250](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230124142855250.png)

### 5. 2012-基于**随机森林**的**目标检测**与定位

基于sift的随机森林的生成

![image-20230124144856069](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230124144856069.png)

![image-20230124144911171](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230124144911171.png)

![image-20230124144838844](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230124144838844.png)

## 舍

[使用随机森林采样多少个特征](https://qastack.cn/datascience/23666/how-many-features-to-sample-using-random-forests)

随机森林模型选择的特征数量大小：

随机选择的特征数量可以通过两种方式影响泛化误差：

- 选择许多特征会增加单个树木的强度，

- 而减少特征数量会导致树木之间的相关性较低，从而增加整个森林的强度。

### 5-其他（英）

1. 2022-改进的**随机森林**用于草地贪夜蛾幼虫期的自动识别（Improved Random Forest for the Automatic Identification of Spodoptera frugiperda Larval Instar Stages）

   The steps of general random forest are as follows.

   (1) Bootstrap resampling [ 43]. A certain proportion of samples are randomly selected
   from the training set to construct the feature subset, and the samples that are not drawn are
   used as the verification set to verify the correctness of the model.

   (2) Decision tree generation. By Using the CART algorithm [44], partial discrete
   features are randomly extracted to obtain feature subsets, and the optimal features in the
   feature subsets are selected as decision tree nodes in each iteration so that the decision tree
   can continuously split and grow without pruning as much as possible.

   (3) Iterative verification. Upon repeating steps 1 and 2, the number of repetitions
   is generally the number of decision trees. The hyperparameter space is constructed in
   the iterative process, and the parameters are adjusted according to the influence of the
   hyperparameters on the accuracy.

   (4) Comprehensive voting. The voting strategy [45 ] of majority voting is adopted
   to comprehensively analyze the classification results of each decision tree, and the final
   training model is obtained to predict the final classification result.

   In order to prevent over-fitting and enhance the identification ability and stability
   of the model, in step (3), the RandomizedSearchCV [ 46 ] and GridSerachCV [ 23] methods
   were proposed to optimize hyperparameters, and the number of iterations of the learner
   was dynamically adjusted according to the training situation. The RandomizedSearchCV
   algorithm [22] is used for randomly searching to narrow the parameter selection range of
   the hyperparameter space for a rough search, and then the GridSerachCV algorithm [23]
   is used for fine searching to construct the optimal hyperparameter set. The combination
   of the two algorithms quickly and efficiently finds the optimal parameters and expands
   the search scope. Furthermore, a 10-fold cross validation was conducted to optimize the
   hyperparameter space and the most suitable combination of hyperparameters was obtained.

   In this paper, a parameter search is performed by setting the ranges of the two parameters of
   n_estimators ([10, 300], stride = 10; [60, 70], stride = 1), and max_depth ([1, 15], stride = 1),
   and finally the optimal hyperparameter combination is obtained, that is, n_estimators = 62
   and max_depth = 7, making the model have the best average identification accuracy and
   auc, and improve average precision, average recall, and average F1 value. The improved
   random forest method is shown in Figure 10.

   ![image-20230123032121393](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123032121393.png)

2. 2019-用于乳房X射线照相肿块检测和分割的多尺度筛选（Multi-scale sifting for mammographic mass detection and segmentation）【Keywords: Mammography, Breast mass detection and segmentation, Morphological sifting, Ensemble learning, Cascaded random forest】

   - Self-grown cascaded random forests（ CasRF）

     Algorithm 1 CasRFs training 伪代码

     ![image-20230123030952891](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123030952891.png)

     ![image-20230123031007003](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20230123031007003.png)

   - 图像分割上做的比较好

3. 2014-车辆分类框架：比较研究（Vehicle classification framework: a comparative study）

### 6-非期刊

1. 【*】2016（英）-实时**目标检测**CS 229课程项目（Real-time Object Detection）【非期刊】

   1. 有一点点sift概念解释，可选。。

      - Object detection is a challenging and exciting task in Computer Vision. Detection can be difficult since there are all kinds of variations in orientation, lighting, background and occlusion that can result in completely different images of the very same object. Now with the advance of deep learning and neural network, we can finally tackle such problems without coming up with various heuristics real-time.

      - Scale Invariant Feature Transform (SIFT) Descriptor

        SIFT Descriptor is also a descriptor built from histogram of gradients, however, the SIFT descriptor has the advantage of being invariant to rotation, translation and resizing.

        SIFT descriptor was used to extract keypoint from the image. We first applied Gaussian filter of different sizes and took their difference. The keypoints were local extrema across each layer of Difference of Gaussian (DoG). After determining a keypoint location and patch size, the dominant direction of gradient was decided and we rotated the patch to have its dominant direction aligned vertically. At last the same procedure of HoG could be carried out to assemble a 128-length feature vector.

      - Faster Region-based Convolutional Neural Network (Faster R-CNN) model——实时上做了努力 

2. 2011（英）-工厂识别任务：使用**SIFT**关键点进行**目标检测**（Using SIFT Keypoints for Object Detection）-【非期刊】

3. 2020-基于像素级特征的遮挡检测与规避方法研究-博士

4. 2019-基于决策森林的回归模型方法研究及应用-博士

5. 2013-基于特征描述子的目标跟踪研究-硕士