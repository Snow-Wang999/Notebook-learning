# 001 深度学习mit系列课程-介绍| 6.S191

MIT Introduction to Deep Learning | 6.S191

- 坐标系：
  - 1、笛卡尔坐标系（cartesian coordinates）
  - 2、极坐标系（polar coordinates）

![image-20221114162816661](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221114162816661.png)

把坐标系从笛卡尔坐标系转为极坐标系，就可以把他们进行分类，用svm算法。

- 表示学习（representation learning）

  这个问题的一个解决方案是使用机器学习不仅发现从表示到输出的映射，而且发现表示本身。这种方法被称为表示学习。学习表示通常会产生比手工设计的表示更好的性能。它们还使 AI 系统能够快速适应新任务，而人为干预最少。表示学习算法可以在几分钟内为简单任务或在数小时到数月内为复杂任务发现一组好的特征。为复杂任务手动设计特征需要大量的人工时间和精力；整个研究人员社区可能需要数十年的时间。

  通过缓慢地转变特征变得越来越抽象，变成人们能够理解。

  ![image-20221114164419728](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221114164419728.png)

  ![image-20221114164445778](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221114164445778.png)

  ![image-20221114165657693](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221114165657693.png)

  ![image-20221114164746530](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221114164746530.png)

  ![image-20221114165708960](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221114165708960.png)

  ![image-20221114165735780](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221114165735780.png)

  ![image-20221114165621383](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221114165621383.png)

  ![image-20221114165746381](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221114165746381.png)

- 本书的高层组织

  ![image-20221114170043769](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221114170043769.png)

  ![image-20221114170132345](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221114170132345.png)

  1、介绍（1->A）

  A、第一部分：应用数学和机器学习基础

  ​	2、线性代数（2->4）

  ​	3、概率和信息理论（3->5）

  ​	4、数字计算（4->5）

  ​	5、机器学习基础（5->B）

  B、第二部分：深度网络：现代实用

  ​	6、深度前馈网络（6->7，8，9，10）

  ​	7、正则化（7->11，12）

  ​	8、优化（8->11，12）

  ​	9、卷积神经网络（9->11，12）

  ​	10、循环神经网络（10->11，12）

  ​	11、实践方法学（11->C）

  ​	12、应用（12->C）

  C、第三部分：深度学习研究

  ​	13、线性因子模型（13->14，16）

  ​	14、自动编码器（14->15）

  ​	15、表征学习

  ​	16、用于深度学习的结构化概率模型（16->17、19）

  ​	17、蒙特卡洛方法（17->18）

  ​	18、面对分区功能（18->20）

  ​	19、近似推理（19->20）

  ​	20、深度生成模型

- 历史：

  研究随着时间的发展

  ![image-20221114171922693](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221114171922693.png)

  ![image-20221114172013260](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221114172013260.png)

  ![image-20221114171936760](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221114171936760.png)

  ![image-20221114172053237](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221114172053237.png)

  增加模型大小

  ![image-20221114172317548](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221114172317548.png)

  ![image-20221114172246380](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221114172246380.png)

  图 1.10：随着时间的推移，每个神经元的连接数。最初，人工神经网络中神经元之间的连接数量受到硬件能力的限制。今天，神经元之间的连接数量主要是设计考虑因素。一些人工神经网络的每个神经元的连接数几乎与猫一样多，而其他神经网络的每个神经元的连接数与小鼠等小型哺乳动物的连接数相当普遍。即使是人脑，每个神经元也没有过多的连接。来自 Wikipedia (2015).

  ```
  1. Adaptive linear element (Widrow and Hoﬀ, 1960)
  2. Neocognitron (Fukushima, 1980)
  3. GPU-accelerated convolutional network (Chellapilla et al., 2006)
  4. Deep Boltzmann machine (Salakhutdinov and Hinton, 2009a)
  5. Unsupervised convolutional network (Jarrett et al., 2009)
  6. GPU-accelerated multilayer perceptron (Ciresan et al., 2010)
  7. Distributed autoencoder (Le et al., 2012)
  8. Multi-GPU convolutional network (Krizhevsky et al., 2012)
  9. COTS HPC unsupervised convolutional network (Coates et al., 2013)
  10. GoogLeNet (Szegedy et al., 2014a)
  ```

  

  1. 自适应线性元素（Widrow 和 Hoff，1960。）

  2. Neocognitron（福岛，1980 年）

  3.  GPU 加速卷积网络 (Chellapilla et al., 2006)
  4. 深度玻尔兹曼机（Salakhutdinov 和 Hinton，2009a）
  5. 无监督卷积网络 (Jarrett et al., 2009)
  6. GPU 加速的多层感知器 (Ciresan et al., 2010)
  7. 分布式自动编码器 (Le et al., 2012)
  8. 多 GPU 卷积网络 (Krizhevsky et al., 2012)
  9. COTS HPC 无监督卷积网络 (Coates et al., 2013)
  10. GoogLeNet（Szegedy 等人，2014a）

- 神经元的数量

  ![image-20221114172349218](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221114172349218.png)

  ![image-20221114172847129](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221114172847129.png)

  图 1.11：随着时间的推移增加神经网络的规模。自引入隐藏单元以来，人工神经网络的规模大约每 2.4 年翻一番。来自维基百科（2015）的生物神经网络大小。

  ```
  1. Perceptron (Rosenblatt, 1958, 1962)
  2. Adaptive linear element (Widrow and Hoﬀ, 1960)
  3. Neocognitron (Fukushima, 1980)
  4. Early back-propagation network (Rumelhart et al., 1986b)
  5. Recurrent neural network for speech recognition (Robinson and Fallside, 1991)
  6. Multilayer perceptron for speech recognition (Bengio et al., 1991)
  7. Mean ﬁeld sigmoid belief network (Saul et al., 1996)
  8. LeNet-5 (LeCun et al., 1998b)
  9. Echo state network (Jaeger and Haas, 2004)
  10. Deep belief network (Hinton et al., 2006)
  11. GPU-accelerated convolutional network (Chellapilla et al., 2006)
  12. Deep Boltzmann machine (Salakhutdinov and Hinton, 2009a)
  13. GPU-accelerated deep belief network (Raina et al., 2009)
  14. Unsupervised convolutional network (Jarrett et al., 2009)
  15. GPU-accelerated multilayer perceptron (Ciresan et al., 2010)
  16. OMP-1 network (Coates and Ng, 2011)
  17. Distributed autoencoder (Le et al., 2012)
  18. Multi-GPU convolutional network (Krizhevsky et al., 2012)
  19. COTS HPC unsupervised convolutional network (Coates et al., 2013)
  20. GoogLeNet (Szegedy et al., 2014a)
  ```

  1. 感知器（罗森布拉特，1958 年，1962 年）
  2. 自适应线性元素（Widrow 和 Hoff，1960）
  3. Neocognitron（福岛，1980）
  4. 早期反向传播网络（Rumelhart 等人，1986b）
  5. 用于语音识别的递归神经网络（Robinson 和 Fallside，1991）
  6. 用于语音识别的多层感知器（Bengio 等人，1991 年）
  7. 平均场 s 型信念网络 (Saul et al., 1996)
  8.  LeNet-5（LeCun 等人，1998b）
  9. 回声状态网络（Jaeger 和 Haas，2004 年）
  10. 深度信念网络 (Hinton et al., 2006)
  11.  GPU 加速卷积网络（Chellapilla 等人，2006 年）
  12. 深度玻尔兹曼机（Salakhutdinov 和 Hinton，2009a）
  13. GPU 加速的深度信念网络（Raina 等人，2009 年）
  14. 无监督卷积网络（Jarrett 等人，2009 年）
  15. GPU 加速的多层感知器（Ciresan 等人，2010 年）
  16. OMP-1 网络（Coates 和 Ng，2011）
  17. 分布式自动编码器（Le 等人，2012 年）
  18. 多 GPU 卷积网络（Krizhevsky 等人，2012 年）
  19. COTS HPC 无监督卷积网络（Coates 等人，2013 年）
  20. GoogLeNet（Szegedy 等人，2014a）

## MIT Introduction to Deep Learning | 6.S191

第一节：深度学习的介绍

![image-20221114180659678](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221114180659678.png)

![image-20221114180854472](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221114180854472.png)

![image-20221114180908717](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221114180908717.png)



why deep learning?

we used to identify characteristics to train the model by ourselves, but right now we want the computer to extract the features by itself and abstract the rules to learn something itself.

![image-20221115122318056](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115122318056.png)

![image-20221115122333389](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115122333389.png)

the basic part of the deep learning:

- big data 
- hardware
- software



感知机（the perceptron：forward propagation）

![image-20221115122514931](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115122514931.png)

![image-20221115122637163](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115122637163.png)

![image-20221115122713517](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115122713517.png)

![image-20221115122731489](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115122731489.png)

![image-20221115122802084](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115122802084.png)

![image-20221115122847783](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115122847783.png)

sigmoid函数使输出0-1，转换为概率

激活函数是引入非线性函数 

![image-20221115123300970](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115123300970.png)

![image-20221115123436194](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115123436194.png)

![image-20221115123425932](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115123425932.png)

![image-20221115123459373](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115123459373.png)

![image-20221115123451720](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115123451720.png)

![image-20221115123558803](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115123558803.png)

用感知器去创建神经网络

![image-20221115123755760](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115123755760.png)

![image-20221115123818468](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115123818468.png)

![image-20221115123854685](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115123854685.png)

```python
class MyDenseLayer(tf.keras.layers.layer):
    def __init__(self, input_dim, output_dim):
        super(MyDenseLayer,self) __init__()
        # initialize weights and bias
        self.W = self.add_weight([input_dim,output_dim])
        self.b = self.add_weight([1,output_dim])
```

![image-20221115124657162](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115124657162.png)

![image-20221115124843771](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115124843771.png)

![image-20221115124857586](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115124857586.png)

![image-20221115125005658](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115125005658.png)

![image-20221115125026373](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115125026373.png)

![image-20221115125047915](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115125047915.png)

![image-20221115125324346](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115125324346.png)

![image-20221115125332096](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115125332096.png)

![image-20221115125408786](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115125408786.png)

![image-20221115125448716](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115125448716.png)

![image-20221115125520324](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115125520324.png)

![image-20221115125616740](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115125616740.png)

![image-20221115125654864](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115125654864.png)

empirical loss经验损失

![image-20221115125737553](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115125737553.png)

![image-20221115125756689](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115125756689.png)

![image-20221115125812823](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115125812823.png)

![image-20221115161155891](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115161155891.png)

$ \underset{c\in C} {\operatorname {argmax}} $
$$
W^*=\underset{W}{\operatorname{argmin}}{\frac{1}{n}{\sum_{i=1}^{n}{L(f(x^{(i)};W),y^{(i)})}}}
$$

$$
W^*=\underset{W}{\operatorname{argmin}{J(W)}}, W =[W^{(0)},W^{(1)},...]
$$

markdown语法argmin

```
#markdown语法argmin
\underset{<constraints>}{\operatorname{<argmax or argmin>}}
```

![image-20221115173405181](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115173405181.png)

![image-20221115173454777](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115173454777.png)

![image-20221115173506560](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115173506560.png)

![image-20221115173514817](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115173514817.png)

![image-20221115173529413](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115173529413.png)

![image-20221115173703262](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115173703262.png)

![image-20221115173823123](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115173823123.png)

![image-20221115173837530](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115173837530.png)

 ![image-20221115173955620](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115173955620.png)

![image-20221115174013291](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115174013291.png)

![image-20221115174031920](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115174031920.png)

![image-20221115174108099](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115174108099.png)

![image-20221115174126226](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115174126226.png)

论文：visualizing the loss landscape of neural nets dec.2017

![image-20221115174304486](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115174304486.png)

![image-20221115174321989](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115174321989.png)

![image-20221115174410864](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115174410864.png)

![image-20221115174450733](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115174450733.png)

![image-20221115174511769](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115174511769.png)

自适应学习率

![image-20221115174528749](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115174528749.png)

梯度下降算法

![image-20221115174602643](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115174602643.png)

tf优化函数：

- tf.keras.optimizers.SGD
- tf.keras.optimizers.Adam
- tf.keras.optimizers.Adadelta
- tf.keras.optimizers.Adagrad
- tf.keras.optimizers.RMSProp

参考文献：

![image-20221115174700376](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115174700376.png)

![image-20221115174945348](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115174945348.png)

![image-20221115175139911](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115175139911.png)

![image-20221115175307962](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115175307962.png)

![image-20221115175331415](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115175331415.png)

![image-20221115175405849](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115175405849.png)

它是一个估计，不是真正的梯度，它很随机也有很多噪声，

![image-20221115175552144](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115175552144.png)

选择一个随机集合的子集合

![image-20221115175653491](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115175653491.png)

mini-batch：通常是32-100，或者更多

![image-20221115175743762](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115175743762.png)

![image-20221115175753473](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115175753473.png)

![image-20221115175805254](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115175805254.png)

![image-20221115175819038](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115175819038.png)

![image-20221115190409563](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115190409563.png)

![image-20221115190426841](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115190426841.png)

![image-20221115190453034](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115190453034.png)

![image-20221115190512650](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115190512650.png)

![image-20221115190534045](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115190534045.png)

![image-20221115190643300](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115190643300.png)

![image-20221115190710970](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115190710970.png)

第二节：

![image-20221115190839834](C:\Users\Myste\AppData\Roaming\Typora\typora-user-images\image-20221115190839834.png)
